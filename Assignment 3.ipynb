{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "remove = dict.fromkeys(map(ord, string.punctuation))\n",
    "\n",
    "\n",
    "#pre-processing the IMDB files \n",
    "with open(\"IMDB-Old-train.txt\", \"r\", encoding=\"utf8\")  as trainI:\n",
    "    trainI =  trainI.read().translate(remove)\n",
    "    trainI = trainI.lower()\n",
    "\n",
    "with open(\"IMDB-Old-valid.txt\", \"r\", encoding=\"utf8\")  as validI:\n",
    "    validI =  validI.read().translate(remove)\n",
    "    validI = validI.lower()\n",
    "    \n",
    "with open(\"IMDB-Old-test.txt\", \"r\", encoding=\"utf8\")  as testI:\n",
    "    testI =  testI.read().translate(remove)\n",
    "    testI = testI.lower()\n",
    "\n",
    "#pre-processing the Yelp files\n",
    "with open(\"yelp-Old-train.txt\", \"r\", encoding=\"utf8\")  as trainY:\n",
    "    trainY =  trainY.read().translate(remove)\n",
    "    trainY = trainY.lower()\n",
    "\n",
    "with open(\"yelp-Old-valid.txt\", \"r\", encoding=\"utf8\")  as validY:\n",
    "    validY =  validY.read().translate(remove)\n",
    "    validY = validY.lower()\n",
    "    \n",
    "with open(\"yelp-Old-test.txt\", \"r\", encoding=\"utf8\")  as testY:\n",
    "    testY =  testY.read().translate(remove)\n",
    "    testY = testY.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"IMDB-vocab.txt\", \"w\", encoding=\"utf8\")  as vocab:\n",
    "    vocabI = Counter(trainI.split()).most_common(10000)\n",
    "    for i in range(10000):\n",
    "        if (vocabI[i][0] != '1' and vocabI[i][0] !='0' and vocabI[i][0] != '\\t'):\n",
    "            vocab.write(vocabI[i][0] + '\\t'+ str(i) +'\\t'+ str(vocabI[i][1])+'\\n')\n",
    "    \n",
    "with open(\"yelp-vocab.txt\", \"w\", encoding=\"utf8\")  as vocab:           \n",
    "    vocabY = Counter(trainY.split()).most_common(11000)\n",
    "    for i in range(10000):\n",
    "        if (vocabY[i][0]!= '0' and vocabY[i][0] != '1' and vocabY[i][0]!='2' and vocabY[i][0] != '3' and vocabY[i][0] != '4' and vocabY[i][0] != '5' and vocabY[i][0]!='\\t'):\n",
    "            vocab.write(vocabY[i][0] + '\\t'+ str(i)  +'\\t'+ str(vocabY[i][1])+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFilesI(filePath, file):\n",
    "    with open(filePath, \"w\", encoding=\"utf8\")  as train:\n",
    "        words = file.split()\n",
    "        for word in words:\n",
    "            if (word != '0' and word != '1'):\n",
    "                for i in range(10000):\n",
    "                    if word == vocabI[i][0]:\n",
    "                        train.write(str(i) + ' ')\n",
    "                        break\n",
    "            else:\n",
    "                train.write('\\t' + word + '\\n')\n",
    "\n",
    "def createFilesY(filePath, file):\n",
    "    with open(filePath, \"w\", encoding=\"utf8\")  as train:\n",
    "        words = file.split()\n",
    "        for word in words:\n",
    "            if (word != '0' and word != '1' and word !='2' and word != '3' and word != '4' and word != '5'):\n",
    "                for i in range(10000):\n",
    "                    if word == vocabY[i][0]:\n",
    "                        train.write(str(i) + ' ')\n",
    "                        break\n",
    "            else:\n",
    "                train.write('\\t' + word + '\\n')\n",
    "\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-cdfbd4266129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#creating datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcreateFilesI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"IMDB-train.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcreateFilesI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"IMDB-valid.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcreateFilesI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"IMDB-test.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-6a7dc597b467>\u001b[0m in \u001b[0;36mcreateFilesI\u001b[1;34m(filePath, file)\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'0'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mvocabI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                         \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#creating datasets\n",
    "\n",
    "createFilesI(\"IMDB-train.txt\", trainI)\n",
    "createFilesI(\"IMDB-valid.txt\", validI)\n",
    "createFilesI(\"IMDB-test.txt\", testI)\n",
    "\n",
    "createFilesY(\"Yelp-train.txt\", trainY)\n",
    "createFilesY(\"Yelp-valid.txt\", validY)\n",
    "createFilesY(\"Yelp-test.txt\", testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = {}\n",
    "vocabulary['IMDB'] = {word[0]: i for i, word in enumerate(vocabI)}\n",
    "vocabulary['Yelp'] = {word[0]: i for i, word in enumerate(vocabY)}\n",
    "\n",
    "IMDB_train = pd.read_csv(\"IMDB-Old-train.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "IMDB_valid = pd.read_csv(\"IMDB-Old-valid.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "IMDB_test = pd.read_csv(\"IMDB-Old-test.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "Yelp_train = pd.read_csv(\"Yelp-Old-train.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "Yelp_valid = pd.read_csv(\"Yelp-Old-valid.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "Yelp_test = pd.read_csv(\"IMDB-Old-test.txt\", sep = '\\t', lineterminator ='\\n', header=None, names = ['review', 'label'])\n",
    "\n",
    "datasets = {\n",
    "    'IMDB':{'train': IMDB_train, 'valid': IMDB_valid, 'test':IMDB_test},\n",
    "    'Yelp':{'train': Yelp_train, 'valid': Yelp_valid, 'test': Yelp_test}\n",
    "}\n",
    "\n",
    "\n",
    "def bow (dataset, vocabulary, xName='review', yName='label'):\n",
    "    BBOW = {}\n",
    "    FBOW = {}\n",
    "    vectorizer = CountVectorizer(vocabulary = vocabulary)\n",
    "    for splitName, split in dataset.items():\n",
    "        vector = vectorizer.fit_transform(split[xName])   \n",
    "        FBOW[splitName] = [normalize(vector.astype(np.float64)),split[yName] ]\n",
    "        vector[vector > 1] = 1\n",
    "        BBOW[splitName] = [vector, split[yName]]\n",
    "    return BBOW, FBOW\n",
    "\n",
    "IMDB_BBOW, IMDB_FBOW = bow (datasets['IMDB'], vocabulary['IMDB'])\n",
    "Yelp_BBOW, Yelp_FBOW = bow(datasets['Yelp'], vocabulary['Yelp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def calculate_base(train, test):\n",
    "    print('F1-score for random and majority class classifier')\n",
    "    dummy = DummyClassifier(strategy = 'uniform')\n",
    "    predict = dummy.fit(train, test).predict(train)\n",
    "    scoreDummy = f1_score(test, predict, average='macro')*100\n",
    "\n",
    "    majority = DummyClassifier(strategy = 'most_frequent')\n",
    "    predict = majority.fit(train, test).predict(train)\n",
    "    scoreMajority = f1_score(test, predict, average='macro')*100\n",
    "\n",
    "    print(scoreDummy, scoreMajority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for  different hyperparameters \n",
    "\n",
    "\n",
    "def get_BernoulliNBParams(train, test, hyperparams):\n",
    "    bern = BernoulliNB()\n",
    "    clf = GridSearchCV(bern, hyperparams, cv=5, scoring='f1_micro', return_train_score=True).fit(train, test)\n",
    "    print('The performance of hyperparameters in Bernoulli Naive Bayes: ')\n",
    "    print(pd.DataFrame.from_dict(clf.cv_results_))\n",
    "    print('\\n')\n",
    "    print('Best hyperparameter:')\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "        \n",
    "def get_DecisionTreesParams(train, test, hyperparams):\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    clf = GridSearchCV(dtc, hyperparams, cv=5, scoring='f1_micro', return_train_score=True).fit(train, test)\n",
    "    print('The performance of hyperparameters in Decision Tree: ')\n",
    "    print(pd.DataFrame.from_dict(clf.cv_results_))\n",
    "    print('\\n')\n",
    "    print('Best hyperparameter:')\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "        \n",
    "def get_SVCParams(train, test, hyperparams):\n",
    "    svm = LinearSVC()\n",
    "    clf = GridSearchCV(svm, hyperparams, cv=5, scoring='f1_micro', return_train_score=True).fit(train, test)\n",
    "    print('The performance of hyperparameters in Linear SVC: ')\n",
    "    print(pd.DataFrame.from_dict(clf.cv_results_))\n",
    "    print('\\n')\n",
    "    print('Best hyperparameter:')\n",
    "    print(clf.best_params_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for random and majority class classifier\n",
      "18.32766877332954 10.426700464723279\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramsha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Bernoulli Naive Bayes: \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
      "0       0.005800      0.001596         0.002598        0.000800       1e-07   \n",
      "1       0.003998      0.000632         0.001602        0.000493       1e-05   \n",
      "2       0.003598      0.000801         0.001603        0.000492      0.0001   \n",
      "3       0.004396      0.001014         0.001602        0.000493       0.001   \n",
      "4       0.005001      0.001547         0.002194        0.000747         0.1   \n",
      "5       0.003999      0.000002         0.001199        0.000399           1   \n",
      "6       0.003798      0.000399         0.001399        0.000490          10   \n",
      "\n",
      "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0   {'alpha': 1e-07}           0.391089              0.365              0.380   \n",
      "1   {'alpha': 1e-05}           0.400990              0.385              0.375   \n",
      "2  {'alpha': 0.0001}           0.405941              0.375              0.375   \n",
      "3   {'alpha': 0.001}           0.420792              0.405              0.395   \n",
      "4     {'alpha': 0.1}           0.410891              0.435              0.400   \n",
      "5       {'alpha': 1}           0.376238              0.390              0.410   \n",
      "6      {'alpha': 10}           0.356436              0.355              0.355   \n",
      "\n",
      "   split3_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0              0.385       ...                   0.383        0.010213   \n",
      "1              0.385       ...                   0.389        0.009716   \n",
      "2              0.390       ...                   0.390        0.013430   \n",
      "3              0.400       ...                   0.406        0.008814   \n",
      "4              0.420       ...                   0.412        0.014568   \n",
      "5              0.410       ...                   0.400        0.014617   \n",
      "6              0.355       ...                   0.356        0.001401   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                6            0.958647             0.96875   \n",
      "1                5            0.956140             0.96875   \n",
      "2                4            0.954887             0.96625   \n",
      "3                2            0.951128             0.96250   \n",
      "4                1            0.913534             0.92000   \n",
      "5                3            0.630326             0.61375   \n",
      "6                7            0.355890             0.35625   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0             0.95375             0.96500            0.968828   \n",
      "1             0.95125             0.96375            0.966334   \n",
      "2             0.94625             0.96250            0.965087   \n",
      "3             0.94125             0.96000            0.961347   \n",
      "4             0.89375             0.91625            0.918953   \n",
      "5             0.66500             0.62125            0.633416   \n",
      "6             0.35625             0.35625            0.355362   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          0.962995         0.005925  \n",
      "1          0.961245         0.006549  \n",
      "2          0.958995         0.007501  \n",
      "3          0.955245         0.008066  \n",
      "4          0.912497         0.009639  \n",
      "5          0.632748         0.017548  \n",
      "6          0.356000         0.000348  \n",
      "\n",
      "[7 rows x 21 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'alpha': 0.1}\n",
      "\n",
      "\n",
      "The performance of hyperparameters in Decision Tree: \n",
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.003599  4.899602e-04         0.001199    4.000671e-04   \n",
      "1         0.003598  4.895517e-04         0.001399    4.894537e-04   \n",
      "2         0.003798  7.473729e-04         0.000999    2.336015e-07   \n",
      "3         0.003398  4.894930e-04         0.000999    5.309834e-07   \n",
      "4         0.003398  4.892787e-04         0.001199    4.001380e-04   \n",
      "5         0.005600  1.353806e-03         0.001196    4.021331e-04   \n",
      "6         0.003802  4.013717e-04         0.000999    4.156970e-07   \n",
      "7         0.003598  4.897457e-04         0.001199    3.999711e-04   \n",
      "8         0.004393  4.849333e-04         0.000999    4.156970e-07   \n",
      "9         0.003598  4.898430e-04         0.001199    3.995181e-04   \n",
      "10        0.003998  5.761645e-07         0.001200    3.998996e-04   \n",
      "11        0.003594  4.868824e-04         0.001399    4.896679e-04   \n",
      "12        0.003998  1.086373e-05         0.000999    5.309834e-07   \n",
      "13        0.003998  1.131562e-05         0.000999    4.862804e-07   \n",
      "14        0.003994  7.607907e-06         0.000999    7.539457e-07   \n",
      "15        0.004601  8.058879e-04         0.001595    4.869986e-04   \n",
      "16        0.004801  1.162570e-03         0.001395    4.860555e-04   \n",
      "17        0.003994  7.874890e-06         0.001399    4.897850e-04   \n",
      "18        0.005396  4.970486e-04         0.001795    1.164897e-03   \n",
      "19        0.005397  8.003784e-04         0.001802    7.516826e-04   \n",
      "20        0.006401  1.014919e-03         0.001604    4.932839e-04   \n",
      "21        0.005799  1.330462e-03         0.001200    4.008057e-04   \n",
      "22        0.004393  4.849229e-04         0.001200    3.997804e-04   \n",
      "23        0.004601  4.925890e-04         0.001000    3.371748e-07   \n",
      "24        0.004398  4.830424e-04         0.001199    3.993037e-04   \n",
      "25        0.004390  4.873553e-04         0.001638    5.263896e-04   \n",
      "26        0.004400  4.930477e-04         0.001000    8.341244e-07   \n",
      "27        0.004398  4.891155e-04         0.001196    4.015658e-04   \n",
      "28        0.004397  4.824063e-04         0.001399    4.896874e-04   \n",
      "29        0.004194  4.015246e-04         0.001399    4.897658e-04   \n",
      "..             ...           ...              ...             ...   \n",
      "170       0.005193  4.013932e-04         0.001799    3.997572e-04   \n",
      "171       0.004797  4.000110e-04         0.000996    7.283288e-06   \n",
      "172       0.005001  7.707376e-06         0.001196    4.019192e-04   \n",
      "173       0.004394  4.923971e-04         0.001399    4.894342e-04   \n",
      "174       0.004797  3.998758e-04         0.000999    3.162980e-07   \n",
      "175       0.005794  7.416338e-04         0.001199    3.994706e-04   \n",
      "176       0.005264  3.974947e-04         0.001399    4.898041e-04   \n",
      "177       0.005193  3.917700e-04         0.001203    3.887091e-04   \n",
      "178       0.004996  6.264557e-04         0.001199    4.000190e-04   \n",
      "179       0.005000  6.941871e-06         0.001200    3.994957e-04   \n",
      "180       0.006815  4.106444e-04         0.001196    3.934148e-04   \n",
      "181       0.006802  4.036210e-04         0.000993    9.124177e-06   \n",
      "182       0.005800  4.021128e-04         0.001403    4.940350e-04   \n",
      "183       0.006196  3.997329e-04         0.000999    3.989506e-07   \n",
      "184       0.005622  5.142154e-04         0.001403    4.947456e-04   \n",
      "185       0.007395  1.029560e-03         0.001403    4.938619e-04   \n",
      "186       0.007191  7.489270e-04         0.001196    3.931046e-04   \n",
      "187       0.006597  4.979192e-04         0.001200    3.999955e-04   \n",
      "188       0.006399  4.796390e-04         0.001403    4.934573e-04   \n",
      "189       0.005596  4.819160e-04         0.001199    3.998519e-04   \n",
      "190       0.008798  7.448940e-04         0.001595    4.867167e-04   \n",
      "191       0.008795  7.486235e-04         0.000997    6.802245e-06   \n",
      "192       0.008002  9.074450e-06         0.000999    5.917394e-07   \n",
      "193       0.006996  8.901592e-04         0.001400    4.894927e-04   \n",
      "194       0.007462  4.626357e-04         0.001000    9.464947e-07   \n",
      "195       0.011200  7.408195e-04         0.001196    3.924133e-04   \n",
      "196       0.008387  4.963581e-04         0.001201    3.995913e-04   \n",
      "197       0.008791  7.379334e-04         0.001200    4.000665e-04   \n",
      "198       0.007599  1.027895e-03         0.001399    4.898431e-04   \n",
      "199       0.007829  7.131377e-04         0.001400    4.897067e-04   \n",
      "\n",
      "    param_max_depth param_max_features param_min_samples_split  \\\n",
      "0                10                  1                       2   \n",
      "1                10                  1                       4   \n",
      "2                10                  1                       6   \n",
      "3                10                  1                       8   \n",
      "4                10                  1                      10   \n",
      "5                10                  4                       2   \n",
      "6                10                  4                       4   \n",
      "7                10                  4                       6   \n",
      "8                10                  4                       8   \n",
      "9                10                  4                      10   \n",
      "10               10                  6                       2   \n",
      "11               10                  6                       4   \n",
      "12               10                  6                       6   \n",
      "13               10                  6                       8   \n",
      "14               10                  6                      10   \n",
      "15               10                 20                       2   \n",
      "16               10                 20                       4   \n",
      "17               10                 20                       6   \n",
      "18               10                 20                       8   \n",
      "19               10                 20                      10   \n",
      "20               10                 40                       2   \n",
      "21               10                 40                       4   \n",
      "22               10                 40                       6   \n",
      "23               10                 40                       8   \n",
      "24               10                 40                      10   \n",
      "25               10                 50                       2   \n",
      "26               10                 50                       4   \n",
      "27               10                 50                       6   \n",
      "28               10                 50                       8   \n",
      "29               10                 50                      10   \n",
      "..              ...                ...                     ...   \n",
      "170              20                  6                       2   \n",
      "171              20                  6                       4   \n",
      "172              20                  6                       6   \n",
      "173              20                  6                       8   \n",
      "174              20                  6                      10   \n",
      "175              20                 20                       2   \n",
      "176              20                 20                       4   \n",
      "177              20                 20                       6   \n",
      "178              20                 20                       8   \n",
      "179              20                 20                      10   \n",
      "180              20                 40                       2   \n",
      "181              20                 40                       4   \n",
      "182              20                 40                       6   \n",
      "183              20                 40                       8   \n",
      "184              20                 40                      10   \n",
      "185              20                 50                       2   \n",
      "186              20                 50                       4   \n",
      "187              20                 50                       6   \n",
      "188              20                 50                       8   \n",
      "189              20                 50                      10   \n",
      "190              20                 80                       2   \n",
      "191              20                 80                       4   \n",
      "192              20                 80                       6   \n",
      "193              20                 80                       8   \n",
      "194              20                 80                      10   \n",
      "195              20                100                       2   \n",
      "196              20                100                       4   \n",
      "197              20                100                       6   \n",
      "198              20                100                       8   \n",
      "199              20                100                      10   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'max_depth': 10, 'max_features': 1, 'min_samp...           0.336634   \n",
      "1    {'max_depth': 10, 'max_features': 1, 'min_samp...           0.361386   \n",
      "2    {'max_depth': 10, 'max_features': 1, 'min_samp...           0.356436   \n",
      "3    {'max_depth': 10, 'max_features': 1, 'min_samp...           0.356436   \n",
      "4    {'max_depth': 10, 'max_features': 1, 'min_samp...           0.356436   \n",
      "5    {'max_depth': 10, 'max_features': 4, 'min_samp...           0.361386   \n",
      "6    {'max_depth': 10, 'max_features': 4, 'min_samp...           0.351485   \n",
      "7    {'max_depth': 10, 'max_features': 4, 'min_samp...           0.351485   \n",
      "8    {'max_depth': 10, 'max_features': 4, 'min_samp...           0.346535   \n",
      "9    {'max_depth': 10, 'max_features': 4, 'min_samp...           0.351485   \n",
      "10   {'max_depth': 10, 'max_features': 6, 'min_samp...           0.371287   \n",
      "11   {'max_depth': 10, 'max_features': 6, 'min_samp...           0.351485   \n",
      "12   {'max_depth': 10, 'max_features': 6, 'min_samp...           0.356436   \n",
      "13   {'max_depth': 10, 'max_features': 6, 'min_samp...           0.376238   \n",
      "14   {'max_depth': 10, 'max_features': 6, 'min_samp...           0.351485   \n",
      "15   {'max_depth': 10, 'max_features': 20, 'min_sam...           0.336634   \n",
      "16   {'max_depth': 10, 'max_features': 20, 'min_sam...           0.341584   \n",
      "17   {'max_depth': 10, 'max_features': 20, 'min_sam...           0.361386   \n",
      "18   {'max_depth': 10, 'max_features': 20, 'min_sam...           0.287129   \n",
      "19   {'max_depth': 10, 'max_features': 20, 'min_sam...           0.371287   \n",
      "20   {'max_depth': 10, 'max_features': 40, 'min_sam...           0.331683   \n",
      "21   {'max_depth': 10, 'max_features': 40, 'min_sam...           0.311881   \n",
      "22   {'max_depth': 10, 'max_features': 40, 'min_sam...           0.346535   \n",
      "23   {'max_depth': 10, 'max_features': 40, 'min_sam...           0.336634   \n",
      "24   {'max_depth': 10, 'max_features': 40, 'min_sam...           0.336634   \n",
      "25   {'max_depth': 10, 'max_features': 50, 'min_sam...           0.351485   \n",
      "26   {'max_depth': 10, 'max_features': 50, 'min_sam...           0.331683   \n",
      "27   {'max_depth': 10, 'max_features': 50, 'min_sam...           0.361386   \n",
      "28   {'max_depth': 10, 'max_features': 50, 'min_sam...           0.321782   \n",
      "29   {'max_depth': 10, 'max_features': 50, 'min_sam...           0.356436   \n",
      "..                                                 ...                ...   \n",
      "170  {'max_depth': 20, 'max_features': 6, 'min_samp...           0.321782   \n",
      "171  {'max_depth': 20, 'max_features': 6, 'min_samp...           0.331683   \n",
      "172  {'max_depth': 20, 'max_features': 6, 'min_samp...           0.321782   \n",
      "173  {'max_depth': 20, 'max_features': 6, 'min_samp...           0.336634   \n",
      "174  {'max_depth': 20, 'max_features': 6, 'min_samp...           0.366337   \n",
      "175  {'max_depth': 20, 'max_features': 20, 'min_sam...           0.321782   \n",
      "176  {'max_depth': 20, 'max_features': 20, 'min_sam...           0.292079   \n",
      "177  {'max_depth': 20, 'max_features': 20, 'min_sam...           0.316832   \n",
      "178  {'max_depth': 20, 'max_features': 20, 'min_sam...           0.341584   \n",
      "179  {'max_depth': 20, 'max_features': 20, 'min_sam...           0.311881   \n",
      "180  {'max_depth': 20, 'max_features': 40, 'min_sam...           0.336634   \n",
      "181  {'max_depth': 20, 'max_features': 40, 'min_sam...           0.326733   \n",
      "182  {'max_depth': 20, 'max_features': 40, 'min_sam...           0.331683   \n",
      "183  {'max_depth': 20, 'max_features': 40, 'min_sam...           0.321782   \n",
      "184  {'max_depth': 20, 'max_features': 40, 'min_sam...           0.326733   \n",
      "185  {'max_depth': 20, 'max_features': 50, 'min_sam...           0.351485   \n",
      "186  {'max_depth': 20, 'max_features': 50, 'min_sam...           0.292079   \n",
      "187  {'max_depth': 20, 'max_features': 50, 'min_sam...           0.321782   \n",
      "188  {'max_depth': 20, 'max_features': 50, 'min_sam...           0.366337   \n",
      "189  {'max_depth': 20, 'max_features': 50, 'min_sam...           0.351485   \n",
      "190  {'max_depth': 20, 'max_features': 80, 'min_sam...           0.326733   \n",
      "191  {'max_depth': 20, 'max_features': 80, 'min_sam...           0.326733   \n",
      "192  {'max_depth': 20, 'max_features': 80, 'min_sam...           0.321782   \n",
      "193  {'max_depth': 20, 'max_features': 80, 'min_sam...           0.341584   \n",
      "194  {'max_depth': 20, 'max_features': 80, 'min_sam...           0.301980   \n",
      "195  {'max_depth': 20, 'max_features': 100, 'min_sa...           0.331683   \n",
      "196  {'max_depth': 20, 'max_features': 100, 'min_sa...           0.405941   \n",
      "197  {'max_depth': 20, 'max_features': 100, 'min_sa...           0.386139   \n",
      "198  {'max_depth': 20, 'max_features': 100, 'min_sa...           0.287129   \n",
      "199  {'max_depth': 20, 'max_features': 100, 'min_sa...           0.336634   \n",
      "\n",
      "     split1_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0                0.340       ...                   0.342        0.006676   \n",
      "1                0.355       ...                   0.348        0.009945   \n",
      "2                0.345       ...                   0.353        0.004895   \n",
      "3                0.340       ...                   0.353        0.011336   \n",
      "4                0.355       ...                   0.347        0.018161   \n",
      "5                0.350       ...                   0.356        0.010332   \n",
      "6                0.325       ...                   0.349        0.012208   \n",
      "7                0.350       ...                   0.347        0.008429   \n",
      "8                0.345       ...                   0.354        0.007297   \n",
      "9                0.345       ...                   0.351        0.004364   \n",
      "10               0.345       ...                   0.350        0.013379   \n",
      "11               0.360       ...                   0.358        0.012247   \n",
      "12               0.350       ...                   0.353        0.004452   \n",
      "13               0.355       ...                   0.360        0.010424   \n",
      "14               0.345       ...                   0.350        0.003302   \n",
      "15               0.325       ...                   0.353        0.020361   \n",
      "16               0.350       ...                   0.347        0.004217   \n",
      "17               0.345       ...                   0.347        0.009469   \n",
      "18               0.335       ...                   0.330        0.024250   \n",
      "19               0.350       ...                   0.361        0.007080   \n",
      "20               0.350       ...                   0.362        0.018983   \n",
      "21               0.415       ...                   0.353        0.033809   \n",
      "22               0.345       ...                   0.347        0.009233   \n",
      "23               0.335       ...                   0.357        0.020221   \n",
      "24               0.305       ...                   0.333        0.014164   \n",
      "25               0.325       ...                   0.330        0.020271   \n",
      "26               0.330       ...                   0.343        0.010062   \n",
      "27               0.360       ...                   0.363        0.008141   \n",
      "28               0.360       ...                   0.347        0.013315   \n",
      "29               0.365       ...                   0.369        0.026475   \n",
      "..                 ...       ...                     ...             ...   \n",
      "170              0.340       ...                   0.336        0.008853   \n",
      "171              0.355       ...                   0.340        0.008232   \n",
      "172              0.345       ...                   0.339        0.013350   \n",
      "173              0.310       ...                   0.349        0.025779   \n",
      "174              0.335       ...                   0.344        0.011816   \n",
      "175              0.350       ...                   0.341        0.011612   \n",
      "176              0.335       ...                   0.328        0.024232   \n",
      "177              0.355       ...                   0.339        0.020524   \n",
      "178              0.365       ...                   0.346        0.013258   \n",
      "179              0.350       ...                   0.341        0.016255   \n",
      "180              0.355       ...                   0.329        0.025408   \n",
      "181              0.370       ...                   0.344        0.016698   \n",
      "182              0.320       ...                   0.332        0.009857   \n",
      "183              0.325       ...                   0.325        0.032375   \n",
      "184              0.390       ...                   0.361        0.029927   \n",
      "185              0.320       ...                   0.333        0.016028   \n",
      "186              0.335       ...                   0.322        0.016749   \n",
      "187              0.345       ...                   0.350        0.017245   \n",
      "188              0.345       ...                   0.348        0.022793   \n",
      "189              0.435       ...                   0.394        0.036010   \n",
      "190              0.270       ...                   0.329        0.032673   \n",
      "191              0.370       ...                   0.335        0.019605   \n",
      "192              0.320       ...                   0.321        0.022999   \n",
      "193              0.350       ...                   0.336        0.026219   \n",
      "194              0.365       ...                   0.338        0.020791   \n",
      "195              0.365       ...                   0.344        0.015121   \n",
      "196              0.355       ...                   0.348        0.034913   \n",
      "197              0.310       ...                   0.334        0.029992   \n",
      "198              0.405       ...                   0.337        0.039962   \n",
      "199              0.280       ...                   0.333        0.038586   \n",
      "\n",
      "     rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                142            0.374687             0.37875   \n",
      "1                 97            0.363409             0.38125   \n",
      "2                 53            0.374687             0.38625   \n",
      "3                 53            0.372180             0.37125   \n",
      "4                105            0.367168             0.36375   \n",
      "5                 36            0.380952             0.37125   \n",
      "6                 88            0.370927             0.39500   \n",
      "7                105            0.364662             0.37500   \n",
      "8                 48            0.387218             0.38625   \n",
      "9                 73            0.375940             0.37250   \n",
      "10                79            0.390977             0.38750   \n",
      "11                27            0.368421             0.37875   \n",
      "12                53            0.404762             0.38875   \n",
      "13                20            0.398496             0.37250   \n",
      "14                79            0.362155             0.38625   \n",
      "15                53            0.406015             0.42125   \n",
      "16               105            0.392231             0.39750   \n",
      "17               105            0.380952             0.40000   \n",
      "18               189            0.423559             0.39000   \n",
      "19                15            0.406015             0.39125   \n",
      "20                13            0.426065             0.43500   \n",
      "21                53            0.419799             0.44625   \n",
      "22               105            0.414787             0.46000   \n",
      "23                30            0.459900             0.44375   \n",
      "24               180            0.395990             0.41125   \n",
      "25               189            0.451128             0.43125   \n",
      "26               139            0.412281             0.42375   \n",
      "27                12            0.422306             0.45375   \n",
      "28               105            0.446115             0.44875   \n",
      "29                 4            0.414787             0.40125   \n",
      "..               ...                 ...                 ...   \n",
      "170              170            0.441103             0.49125   \n",
      "171              155            0.442356             0.39750   \n",
      "172              160            0.439850             0.42250   \n",
      "173               88            0.417293             0.45625   \n",
      "174              131            0.398496             0.38125   \n",
      "175              149            0.493734             0.49625   \n",
      "176              195            0.521303             0.47750   \n",
      "177              160            0.457393             0.47375   \n",
      "178              121            0.441103             0.44875   \n",
      "179              149            0.476190             0.43750   \n",
      "180              192            0.573935             0.57000   \n",
      "181              131            0.503759             0.53625   \n",
      "182              185            0.456140             0.56250   \n",
      "183              196            0.516291             0.46125   \n",
      "184               15            0.501253             0.50875   \n",
      "185              180            0.505013             0.57000   \n",
      "186              198            0.576441             0.49875   \n",
      "187               79            0.527569             0.52250   \n",
      "188               97            0.526316             0.54000   \n",
      "189                1            0.536341             0.51125   \n",
      "190              192            0.551378             0.58750   \n",
      "191              174            0.581454             0.64500   \n",
      "192              199            0.604010             0.58375   \n",
      "193              170            0.459900             0.56375   \n",
      "194              163            0.602757             0.49000   \n",
      "195              131            0.634085             0.64375   \n",
      "196               97            0.617794             0.54250   \n",
      "197              176            0.606516             0.61250   \n",
      "198              165            0.496241             0.59500   \n",
      "199              180            0.507519             0.56250   \n",
      "\n",
      "     split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0               0.37750             0.38000            0.376559   \n",
      "1               0.37500             0.36625            0.375312   \n",
      "2               0.36375             0.37125            0.376559   \n",
      "3               0.38250             0.37000            0.374065   \n",
      "4               0.37375             0.36250            0.382793   \n",
      "5               0.38875             0.37250            0.397756   \n",
      "6               0.37875             0.39500            0.372818   \n",
      "7               0.36875             0.37500            0.377805   \n",
      "8               0.38625             0.38125            0.376559   \n",
      "9               0.37125             0.37375            0.371571   \n",
      "10              0.38125             0.38375            0.382793   \n",
      "11              0.36875             0.39000            0.376559   \n",
      "12              0.36875             0.37750            0.371571   \n",
      "13              0.38000             0.38375            0.377805   \n",
      "14              0.37125             0.38000            0.375312   \n",
      "15              0.39875             0.42125            0.406484   \n",
      "16              0.42500             0.39250            0.390274   \n",
      "17              0.40125             0.41625            0.402743   \n",
      "18              0.39500             0.37125            0.392768   \n",
      "19              0.42750             0.38000            0.380299   \n",
      "20              0.43625             0.42500            0.406484   \n",
      "21              0.44250             0.41500            0.402743   \n",
      "22              0.41375             0.43125            0.427681   \n",
      "23              0.42875             0.41500            0.386534   \n",
      "24              0.39500             0.41125            0.413965   \n",
      "25              0.43250             0.41625            0.408978   \n",
      "26              0.41125             0.42250            0.392768   \n",
      "27              0.41625             0.41125            0.418953   \n",
      "28              0.39500             0.42125            0.432668   \n",
      "29              0.41250             0.45000            0.403990   \n",
      "..                  ...                 ...                 ...   \n",
      "170             0.43500             0.43500            0.432668   \n",
      "171             0.41125             0.43125            0.427681   \n",
      "172             0.38875             0.45000            0.418953   \n",
      "173             0.42250             0.38375            0.427681   \n",
      "174             0.43250             0.40750            0.389027   \n",
      "175             0.50500             0.46000            0.486284   \n",
      "176             0.45750             0.50375            0.504988   \n",
      "177             0.51500             0.45125            0.475062   \n",
      "178             0.46875             0.45250            0.446384   \n",
      "179             0.46000             0.41000            0.465087   \n",
      "180             0.52375             0.56125            0.532419   \n",
      "181             0.48750             0.52625            0.512469   \n",
      "182             0.52500             0.54000            0.522444   \n",
      "183             0.52000             0.52000            0.541147   \n",
      "184             0.50750             0.50125            0.486284   \n",
      "185             0.56875             0.53500            0.627182   \n",
      "186             0.56375             0.56000            0.610973   \n",
      "187             0.56875             0.55125            0.480050   \n",
      "188             0.52375             0.54500            0.558603   \n",
      "189             0.47000             0.42500            0.498753   \n",
      "190             0.58375             0.57125            0.624688   \n",
      "191             0.60125             0.55000            0.617207   \n",
      "192             0.58125             0.51125            0.552369   \n",
      "193             0.60000             0.52250            0.568579   \n",
      "194             0.54750             0.55500            0.509975   \n",
      "195             0.66000             0.65250            0.708229   \n",
      "196             0.63750             0.52125            0.537406   \n",
      "197             0.52750             0.60500            0.558603   \n",
      "198             0.52375             0.57875            0.561097   \n",
      "199             0.59750             0.56625            0.633416   \n",
      "\n",
      "     mean_train_score  std_train_score  \n",
      "0            0.377499         0.001823  \n",
      "1            0.372244         0.006513  \n",
      "2            0.374499         0.007327  \n",
      "3            0.373999         0.004453  \n",
      "4            0.369992         0.007497  \n",
      "5            0.382242         0.010004  \n",
      "6            0.382499         0.010528  \n",
      "7            0.372243         0.004813  \n",
      "8            0.383505         0.004054  \n",
      "9            0.373002         0.001706  \n",
      "10           0.385254         0.003526  \n",
      "11           0.376496         0.007908  \n",
      "12           0.382267         0.013175  \n",
      "13           0.382510         0.008783  \n",
      "14           0.374993         0.008133  \n",
      "15           0.410750         0.009001  \n",
      "16           0.399501         0.012971  \n",
      "17           0.400239         0.011275  \n",
      "18           0.394515         0.016784  \n",
      "19           0.397013         0.017958  \n",
      "20           0.425760         0.010655  \n",
      "21           0.425259         0.016613  \n",
      "22           0.429494         0.016740  \n",
      "23           0.426787         0.025089  \n",
      "24           0.405491         0.008228  \n",
      "25           0.428021         0.014599  \n",
      "26           0.412510         0.011113  \n",
      "27           0.424502         0.015065  \n",
      "28           0.428757         0.019556  \n",
      "29           0.416505         0.017494  \n",
      "..                ...              ...  \n",
      "170          0.447004         0.022299  \n",
      "171          0.422007         0.015799  \n",
      "172          0.424010         0.020964  \n",
      "173          0.421495         0.023193  \n",
      "174          0.401755         0.017728  \n",
      "175          0.488254         0.015340  \n",
      "176          0.493008         0.022631  \n",
      "177          0.474491         0.022246  \n",
      "178          0.451497         0.009385  \n",
      "179          0.449756         0.023535  \n",
      "180          0.552271         0.020356  \n",
      "181          0.513246         0.017040  \n",
      "182          0.521217         0.035519  \n",
      "183          0.511738         0.026725  \n",
      "184          0.501007         0.007987  \n",
      "185          0.561189         0.040820  \n",
      "186          0.561983         0.036372  \n",
      "187          0.530024         0.030034  \n",
      "188          0.538734         0.012762  \n",
      "189          0.488269         0.038172  \n",
      "190          0.583713         0.024059  \n",
      "191          0.598982         0.032129  \n",
      "192          0.566526         0.032169  \n",
      "193          0.542946         0.048290  \n",
      "194          0.541046         0.039027  \n",
      "195          0.659713         0.025759  \n",
      "196          0.571290         0.046963  \n",
      "197          0.582024         0.033400  \n",
      "198          0.550968         0.036192  \n",
      "199          0.573437         0.041697  \n",
      "\n",
      "[200 rows x 23 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'max_depth': 20, 'max_features': 50, 'min_samples_split': 10}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Linear SVC: \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0        0.012988      0.000006         0.001001    8.869684e-07   1e-05   \n",
      "1        0.012614      0.000510         0.001001    4.101908e-07   1e-05   \n",
      "2        0.011600      0.001356         0.000997    6.940561e-06   1e-05   \n",
      "3        0.009002      0.002094         0.001000    6.322596e-04   1e-05   \n",
      "4        0.007393      0.000800         0.001400    4.894695e-04   1e-05   \n",
      "5        0.016390      0.000490         0.001000    7.136645e-07   0.001   \n",
      "6        0.014396      0.000486         0.000996    7.366478e-06   0.001   \n",
      "7        0.011800      0.000412         0.000396    4.856339e-04   0.001   \n",
      "8        0.007988      0.000014         0.000804    4.022559e-04   0.001   \n",
      "9        0.006200      0.000406         0.001001    7.599534e-07   0.001   \n",
      "10       0.021017      0.000668         0.000800    4.001390e-04    0.01   \n",
      "11       0.019389      0.000498         0.001001    2.780415e-07    0.01   \n",
      "12       0.013815      0.000414         0.000800    4.000907e-04    0.01   \n",
      "13       0.008798      0.000402         0.000997    7.461245e-06    0.01   \n",
      "14       0.006600      0.000493         0.000600    4.898626e-04    0.01   \n",
      "15       0.041172      0.000401         0.000803    4.016307e-04       1   \n",
      "16       0.034580      0.000490         0.000997    7.435297e-06       1   \n",
      "17       0.022231      0.000670         0.000803    4.017330e-04       1   \n",
      "18       0.012187      0.001169         0.001016    3.064064e-05       1   \n",
      "19       0.006200      0.000398         0.000800    4.001634e-04       1   \n",
      "20       0.047214      0.002984         0.000996    8.160187e-06       2   \n",
      "21       0.040577      0.001629         0.001000    6.319576e-04       2   \n",
      "22       0.023786      0.001172         0.000997    7.268287e-06       2   \n",
      "23       0.011825      0.000322         0.001004    6.798233e-06       2   \n",
      "24       0.006396      0.000504         0.000800    4.001860e-04       2   \n",
      "25       0.060162      0.010411         0.000800    4.000440e-04      10   \n",
      "26       0.049620      0.008405         0.000601    4.903297e-04      10   \n",
      "27       0.027384      0.003193         0.000800    4.001149e-04      10   \n",
      "28       0.011996      0.000017         0.000800    4.001387e-04      10   \n",
      "29       0.006400      0.000494         0.000801    4.005683e-04      10   \n",
      "\n",
      "   param_tol                       params  split0_test_score  \\\n",
      "0      1e-05   {'C': 1e-05, 'tol': 1e-05}           0.356436   \n",
      "1     0.0001  {'C': 1e-05, 'tol': 0.0001}           0.356436   \n",
      "2       0.01    {'C': 1e-05, 'tol': 0.01}           0.356436   \n",
      "3          1       {'C': 1e-05, 'tol': 1}           0.356436   \n",
      "4         10      {'C': 1e-05, 'tol': 10}           0.356436   \n",
      "5      1e-05   {'C': 0.001, 'tol': 1e-05}           0.415842   \n",
      "6     0.0001  {'C': 0.001, 'tol': 0.0001}           0.415842   \n",
      "7       0.01    {'C': 0.001, 'tol': 0.01}           0.415842   \n",
      "8          1       {'C': 0.001, 'tol': 1}           0.420792   \n",
      "9         10      {'C': 0.001, 'tol': 10}           0.435644   \n",
      "10     1e-05    {'C': 0.01, 'tol': 1e-05}           0.455446   \n",
      "11    0.0001   {'C': 0.01, 'tol': 0.0001}           0.455446   \n",
      "12      0.01     {'C': 0.01, 'tol': 0.01}           0.455446   \n",
      "13         1        {'C': 0.01, 'tol': 1}           0.460396   \n",
      "14        10       {'C': 0.01, 'tol': 10}           0.445545   \n",
      "15     1e-05       {'C': 1, 'tol': 1e-05}           0.376238   \n",
      "16    0.0001      {'C': 1, 'tol': 0.0001}           0.376238   \n",
      "17      0.01        {'C': 1, 'tol': 0.01}           0.376238   \n",
      "18         1           {'C': 1, 'tol': 1}           0.400990   \n",
      "19        10          {'C': 1, 'tol': 10}           0.381188   \n",
      "20     1e-05       {'C': 2, 'tol': 1e-05}           0.386139   \n",
      "21    0.0001      {'C': 2, 'tol': 0.0001}           0.386139   \n",
      "22      0.01        {'C': 2, 'tol': 0.01}           0.386139   \n",
      "23         1           {'C': 2, 'tol': 1}           0.396040   \n",
      "24        10          {'C': 2, 'tol': 10}           0.391089   \n",
      "25     1e-05      {'C': 10, 'tol': 1e-05}           0.386139   \n",
      "26    0.0001     {'C': 10, 'tol': 0.0001}           0.386139   \n",
      "27      0.01       {'C': 10, 'tol': 0.01}           0.386139   \n",
      "28         1          {'C': 10, 'tol': 1}           0.391089   \n",
      "29        10         {'C': 10, 'tol': 10}           0.410891   \n",
      "\n",
      "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
      "0               0.355              0.355       ...                   0.356   \n",
      "1               0.355              0.355       ...                   0.356   \n",
      "2               0.355              0.355       ...                   0.356   \n",
      "3               0.355              0.355       ...                   0.356   \n",
      "4               0.355              0.355       ...                   0.356   \n",
      "5               0.465              0.440       ...                   0.421   \n",
      "6               0.465              0.440       ...                   0.421   \n",
      "7               0.465              0.440       ...                   0.421   \n",
      "8               0.465              0.425       ...                   0.421   \n",
      "9               0.465              0.440       ...                   0.437   \n",
      "10              0.475              0.455       ...                   0.451   \n",
      "11              0.475              0.455       ...                   0.451   \n",
      "12              0.475              0.455       ...                   0.451   \n",
      "13              0.465              0.450       ...                   0.450   \n",
      "14              0.435              0.415       ...                   0.421   \n",
      "15              0.420              0.420       ...                   0.402   \n",
      "16              0.420              0.420       ...                   0.402   \n",
      "17              0.420              0.420       ...                   0.402   \n",
      "18              0.425              0.420       ...                   0.412   \n",
      "19              0.465              0.400       ...                   0.409   \n",
      "20              0.420              0.405       ...                   0.399   \n",
      "21              0.420              0.405       ...                   0.399   \n",
      "22              0.420              0.405       ...                   0.399   \n",
      "23              0.425              0.410       ...                   0.405   \n",
      "24              0.435              0.360       ...                   0.395   \n",
      "25              0.425              0.405       ...                   0.400   \n",
      "26              0.425              0.405       ...                   0.400   \n",
      "27              0.425              0.410       ...                   0.401   \n",
      "28              0.425              0.410       ...                   0.401   \n",
      "29              0.400              0.390       ...                   0.392   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.001401               26            0.355890             0.35625   \n",
      "1         0.001401               26            0.355890             0.35625   \n",
      "2         0.001401               26            0.355890             0.35625   \n",
      "3         0.001401               26            0.355890             0.35625   \n",
      "4         0.001401               26            0.355890             0.35625   \n",
      "5         0.033414                6            0.670426             0.68000   \n",
      "6         0.033414                6            0.670426             0.68000   \n",
      "7         0.033414                6            0.670426             0.68000   \n",
      "8         0.032529                6            0.666667             0.68750   \n",
      "9         0.017498                5            0.605263             0.66000   \n",
      "10        0.015117                1            0.946115             0.96625   \n",
      "11        0.015117                1            0.946115             0.96625   \n",
      "12        0.015117                1            0.946115             0.96625   \n",
      "13        0.015841                4            0.947368             0.96625   \n",
      "14        0.027482                6            0.828321             0.83375   \n",
      "15        0.029234               14            1.000000             1.00000   \n",
      "16        0.029234               14            1.000000             1.00000   \n",
      "17        0.029234               14            1.000000             1.00000   \n",
      "18        0.025697               11            1.000000             1.00000   \n",
      "19        0.034780               12            0.662907             0.77250   \n",
      "20        0.027024               21            1.000000             1.00000   \n",
      "21        0.027024               21            1.000000             1.00000   \n",
      "22        0.027024               21            1.000000             1.00000   \n",
      "23        0.023769               13            1.000000             1.00000   \n",
      "24        0.024093               24            0.805764             0.82750   \n",
      "25        0.027862               19            1.000000             1.00000   \n",
      "26        0.027862               19            1.000000             1.00000   \n",
      "27        0.028112               17            1.000000             1.00000   \n",
      "28        0.026693               17            1.000000             1.00000   \n",
      "29        0.013932               25            0.820802             0.71625   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0              0.35625             0.35625            0.355362   \n",
      "1              0.35625             0.35625            0.355362   \n",
      "2              0.35625             0.35625            0.355362   \n",
      "3              0.35625             0.35625            0.355362   \n",
      "4              0.35625             0.35625            0.355362   \n",
      "5              0.67125             0.67000            0.683292   \n",
      "6              0.67125             0.67000            0.683292   \n",
      "7              0.67125             0.67000            0.684539   \n",
      "8              0.68500             0.68000            0.684539   \n",
      "9              0.56750             0.61125            0.703242   \n",
      "10             0.96250             0.95500            0.962594   \n",
      "11             0.96250             0.95500            0.962594   \n",
      "12             0.96250             0.95500            0.962594   \n",
      "13             0.96000             0.95500            0.962594   \n",
      "14             0.88750             0.68375            0.910224   \n",
      "15             1.00000             1.00000            1.000000   \n",
      "16             1.00000             1.00000            1.000000   \n",
      "17             1.00000             1.00000            1.000000   \n",
      "18             1.00000             1.00000            1.000000   \n",
      "19             0.84500             0.86125            0.840399   \n",
      "20             1.00000             1.00000            1.000000   \n",
      "21             1.00000             1.00000            1.000000   \n",
      "22             1.00000             1.00000            1.000000   \n",
      "23             1.00000             1.00000            1.000000   \n",
      "24             0.79125             0.77625            0.840399   \n",
      "25             1.00000             1.00000            1.000000   \n",
      "26             1.00000             1.00000            1.000000   \n",
      "27             1.00000             1.00000            1.000000   \n",
      "28             1.00000             1.00000            1.000000   \n",
      "29             0.81000             0.81750            0.809227   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.356000         0.000348  \n",
      "1           0.356000         0.000348  \n",
      "2           0.356000         0.000348  \n",
      "3           0.356000         0.000348  \n",
      "4           0.356000         0.000348  \n",
      "5           0.674994         0.005545  \n",
      "6           0.674994         0.005545  \n",
      "7           0.675243         0.005927  \n",
      "8           0.680741         0.007442  \n",
      "9           0.629451         0.047186  \n",
      "10          0.958492         0.007190  \n",
      "11          0.958492         0.007190  \n",
      "12          0.958492         0.007190  \n",
      "13          0.958242         0.006556  \n",
      "14          0.828709         0.078917  \n",
      "15          1.000000         0.000000  \n",
      "16          1.000000         0.000000  \n",
      "17          1.000000         0.000000  \n",
      "18          1.000000         0.000000  \n",
      "19          0.796411         0.073342  \n",
      "20          1.000000         0.000000  \n",
      "21          1.000000         0.000000  \n",
      "22          1.000000         0.000000  \n",
      "23          1.000000         0.000000  \n",
      "24          0.808233         0.023338  \n",
      "25          1.000000         0.000000  \n",
      "26          1.000000         0.000000  \n",
      "27          1.000000         0.000000  \n",
      "28          1.000000         0.000000  \n",
      "29          0.794756         0.039499  \n",
      "\n",
      "[30 rows x 22 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'C': 0.01, 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "calculate_base(Yelp_BBOW['train'][0],Yelp_BBOW['train'][1])\n",
    "print('\\n')\n",
    "\n",
    "parametersBN = {'alpha': [0.0000001, 0.00001, 0.0001, 0.001, 0.1, 1, 10]}\n",
    "get_BernoulliNBParams(Yelp_BBOW['valid'][0], Yelp_BBOW['valid'][1],parametersBN)\n",
    "print('\\n')\n",
    "\n",
    "parametersDTC = {'max_depth': [10,12,14,16,20], 'min_samples_split': [2,4,6,8,10], \"max_features\": [1,4, 6, 20, 40, 50, 80, 100]}\n",
    "get_DecisionTreesParams(Yelp_BBOW['valid'][0],Yelp_BBOW['valid'][1], parametersDTC)\n",
    "print('\\n')\n",
    "\n",
    "parametersSVC = {'tol': [0.00001, 0.0001, 0.01, 1, 10], 'C': [0.00001, 0.001, 0.01, 1, 2, 10]}\n",
    "get_SVCParams(Yelp_BBOW['valid'][0],Yelp_BBOW['valid'][1], parametersSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_BernoulliNB(train, test, hyperparameter):\n",
    "    print('F1-score for bernoulli for hyperparameter: '+str(hyperparameter))\n",
    "    bern = BernoulliNB(alpha = hyperparameter)\n",
    "    predict = bern.fit(train, test).predict(train)\n",
    "    score = f1_score(test, predict, average='micro')*100\n",
    "    print(score)\n",
    "\n",
    "def calculate_DecisionTrees(train, test, maxDepth, maxFeatures, minSamplesSplit):\n",
    "    print('F1-score for Decision Trees for hyperparameter: '+str(maxDepth)+ \" \"  +  str(maxFeatures) + \" \"+ str(minSamplesSplit))\n",
    "    tree = DecisionTreeClassifier(max_depth=maxDepth, max_features=maxFeatures, min_samples_split=minSamplesSplit)\n",
    "    predict = tree.fit(train, test).predict(train) \n",
    "    score = f1_score(test, predict, average='micro')*100\n",
    "    print(score)\n",
    "    \n",
    "def calculate_SVC(train, test, c, tolerance):\n",
    "    print('F1-score for Linear SVC for hyperparameter: '+str(c) + \" \"+ str(tolerance))\n",
    "    svc = LinearSVC(C=c, tol=tolerance)\n",
    "    predict = svc.fit(train,test).predict(train)\n",
    "    score = f1_score(test, predict, average='micro')*100\n",
    "    print(score)\n",
    "\n",
    "def calculate_GaussianNB(train, test):\n",
    "    print('F1-score for Gaussian:')\n",
    "    gNB = GaussianNB()\n",
    "    predict = gNB.fit(train,test).predict(train)\n",
    "    score = f1_score(test, predict, average='micro')*100\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores for train set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 0.1\n",
      "71.15714285714286\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 12 40 4\n",
      "38.457142857142856\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1e-05\n",
      "84.78571428571429\n",
      "\n",
      "\n",
      "F1-scores for valid set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 0.1\n",
      "91.10000000000001\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 12 40 4\n",
      "41.0\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1e-05\n",
      "94.89999999999999\n",
      "\n",
      "\n",
      "F1-scores for test set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 0.1\n",
      "86.56800000000001\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 12 40 4\n",
      "65.164\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1e-05\n",
      "93.64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1-scores for train set\\n')\n",
    "calculate_BernoulliNB(Yelp_BBOW['train'][0], Yelp_BBOW['train'][1], 0.1)\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(Yelp_BBOW['train'][0], Yelp_BBOW['train'][1], 12, 40, 4)\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_BBOW['train'][0], Yelp_BBOW['train'][1], 0.01, 1e-05)\n",
    "print('\\n')\n",
    "print('F1-scores for valid set\\n')\n",
    "calculate_BernoulliNB(Yelp_BBOW['valid'][0], Yelp_BBOW['valid'][1], 0.1)\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(Yelp_BBOW['valid'][0], Yelp_BBOW['valid'][1], 12, 40, 4)\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_BBOW['valid'][0], Yelp_BBOW['valid'][1], 0.01, 1e-05)\n",
    "print('\\n')\n",
    "print('F1-scores for test set\\n')\n",
    "calculate_BernoulliNB(Yelp_BBOW['test'][0], Yelp_BBOW['test'][1], 0.1 )\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(Yelp_BBOW['test'][0], Yelp_BBOW['test'][1], 12, 40, 4)\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_BBOW['test'][0], Yelp_BBOW['test'][1], 0.01, 1e-05)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Decision Tree: \n",
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.007194      0.002230         0.001602    4.919825e-04   \n",
      "1         0.004801      0.000402         0.000999    6.325960e-07   \n",
      "2         0.005197      0.000979         0.001003    6.902455e-06   \n",
      "3         0.004194      0.000393         0.001199    3.999240e-04   \n",
      "4         0.004801      0.000749         0.001405    4.964871e-04   \n",
      "5         0.004590      0.000491         0.001196    4.013300e-04   \n",
      "6         0.003798      0.000400         0.001598    4.973404e-04   \n",
      "7         0.005993      0.000638         0.001599    4.822840e-04   \n",
      "8         0.005592      0.000487         0.001000    1.168008e-07   \n",
      "9         0.005204      0.000397         0.001397    4.848697e-04   \n",
      "10        0.005400      0.000494         0.001200    4.000664e-04   \n",
      "11        0.005396      0.000490         0.001000    7.893059e-07   \n",
      "12        0.005593      0.000494         0.001196    4.104192e-04   \n",
      "13        0.005393      0.000801         0.001199    3.994704e-04   \n",
      "14        0.006000      0.000013         0.001196    4.020139e-04   \n",
      "15        0.006181      0.000409         0.001002    5.608870e-06   \n",
      "16        0.005397      0.000489         0.001199    3.996137e-04   \n",
      "17        0.006196      0.000400         0.000999    5.309834e-07   \n",
      "18        0.005596      0.000491         0.001396    4.935867e-04   \n",
      "19        0.005794      0.000398         0.001003    6.652861e-06   \n",
      "20        0.006193      0.001463         0.001400    4.890254e-04   \n",
      "21        0.006795      0.000399         0.001197    3.923695e-04   \n",
      "22        0.006596      0.000489         0.001200    3.995420e-04   \n",
      "23        0.006000      0.000007         0.001199    3.998521e-04   \n",
      "24        0.006603      0.000803         0.001200    3.994948e-04   \n",
      "25        0.005996      0.000011         0.001000    3.568323e-07   \n",
      "26        0.005997      0.000012         0.001199    3.997330e-04   \n",
      "27        0.005992      0.000889         0.009591    1.568876e-02   \n",
      "28        0.008799      0.000402         0.001396    4.859607e-04   \n",
      "29        0.006596      0.000490         0.001200    3.998998e-04   \n",
      "..             ...           ...              ...             ...   \n",
      "250       0.008194      0.000748         0.001200    3.998757e-04   \n",
      "251       0.007998      0.001094         0.001400    4.901355e-04   \n",
      "252       0.011998      0.000632         0.001998    1.094496e-03   \n",
      "253       0.010191      0.000411         0.001598    4.905662e-04   \n",
      "254       0.008798      0.000749         0.001604    4.930504e-04   \n",
      "255       0.011996      0.005435         0.003798    4.619102e-03   \n",
      "256       0.012392      0.002868         0.002799    7.488152e-04   \n",
      "257       0.034380      0.011735         0.002398    1.019432e-03   \n",
      "258       0.020388      0.011103         0.001800    7.484055e-04   \n",
      "259       0.017194      0.003061         0.002196    9.766801e-04   \n",
      "260       0.016593      0.002574         0.003398    1.628090e-03   \n",
      "261       0.015393      0.002420         0.002597    4.922291e-04   \n",
      "262       0.013992      0.004145         0.001600    4.889477e-04   \n",
      "263       0.009793      0.003186         0.001600    4.896489e-04   \n",
      "264       0.008594      0.001356         0.001599    4.896679e-04   \n",
      "265       0.006192      0.000744         0.001204    3.973260e-04   \n",
      "266       0.016590      0.003202         0.001596    4.871382e-04   \n",
      "267       0.024986      0.018156         0.004198    5.414796e-03   \n",
      "268       0.024985      0.008644         0.002400    1.356255e-03   \n",
      "269       0.018989      0.003223         0.002799    1.938292e-03   \n",
      "270       0.022268      0.005406         0.002599    1.742318e-03   \n",
      "271       0.022188      0.008325         0.001999    2.076296e-06   \n",
      "272       0.016276      0.004751         0.001799    3.996394e-04   \n",
      "273       0.034980      0.007372         0.002599    7.990958e-04   \n",
      "274       0.013791      0.004618         0.001200    3.997333e-04   \n",
      "275       0.011193      0.000980         0.001000    4.862804e-07   \n",
      "276       0.014795      0.001716         0.003002    1.785914e-03   \n",
      "277       0.018189      0.004398         0.002599    1.355742e-03   \n",
      "278       0.019388      0.015847         0.001600    4.895121e-04   \n",
      "279       0.009794      0.002134         0.001399    4.898628e-04   \n",
      "\n",
      "    param_max_depth param_max_features param_min_samples_split  \\\n",
      "0                40                  1                      10   \n",
      "1                40                  1                      20   \n",
      "2                40                  1                      30   \n",
      "3                40                  1                      40   \n",
      "4                40                  1                      50   \n",
      "5                40                  1                      60   \n",
      "6                40                  1                     100   \n",
      "7                40                  4                      10   \n",
      "8                40                  4                      20   \n",
      "9                40                  4                      30   \n",
      "10               40                  4                      40   \n",
      "11               40                  4                      50   \n",
      "12               40                  4                      60   \n",
      "13               40                  4                     100   \n",
      "14               40                  6                      10   \n",
      "15               40                  6                      20   \n",
      "16               40                  6                      30   \n",
      "17               40                  6                      40   \n",
      "18               40                  6                      50   \n",
      "19               40                  6                      60   \n",
      "20               40                  6                     100   \n",
      "21               40                 20                      10   \n",
      "22               40                 20                      20   \n",
      "23               40                 20                      30   \n",
      "24               40                 20                      40   \n",
      "25               40                 20                      50   \n",
      "26               40                 20                      60   \n",
      "27               40                 20                     100   \n",
      "28               40                 40                      10   \n",
      "29               40                 40                      20   \n",
      "..              ...                ...                     ...   \n",
      "250             100                 20                      60   \n",
      "251             100                 20                     100   \n",
      "252             100                 40                      10   \n",
      "253             100                 40                      20   \n",
      "254             100                 40                      30   \n",
      "255             100                 40                      40   \n",
      "256             100                 40                      50   \n",
      "257             100                 40                      60   \n",
      "258             100                 40                     100   \n",
      "259             100                 50                      10   \n",
      "260             100                 50                      20   \n",
      "261             100                 50                      30   \n",
      "262             100                 50                      40   \n",
      "263             100                 50                      50   \n",
      "264             100                 50                      60   \n",
      "265             100                 50                     100   \n",
      "266             100                 80                      10   \n",
      "267             100                 80                      20   \n",
      "268             100                 80                      30   \n",
      "269             100                 80                      40   \n",
      "270             100                 80                      50   \n",
      "271             100                 80                      60   \n",
      "272             100                 80                     100   \n",
      "273             100                100                      10   \n",
      "274             100                100                      20   \n",
      "275             100                100                      30   \n",
      "276             100                100                      40   \n",
      "277             100                100                      50   \n",
      "278             100                100                      60   \n",
      "279             100                100                     100   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.346535   \n",
      "1    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.316832   \n",
      "2    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.356436   \n",
      "3    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.361386   \n",
      "4    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.351485   \n",
      "5    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.351485   \n",
      "6    {'max_depth': 40, 'max_features': 1, 'min_samp...           0.316832   \n",
      "7    {'max_depth': 40, 'max_features': 4, 'min_samp...           0.361386   \n",
      "8    {'max_depth': 40, 'max_features': 4, 'min_samp...           0.346535   \n",
      "9    {'max_depth': 40, 'max_features': 4, 'min_samp...           0.331683   \n",
      "10   {'max_depth': 40, 'max_features': 4, 'min_samp...           0.341584   \n",
      "11   {'max_depth': 40, 'max_features': 4, 'min_samp...           0.282178   \n",
      "12   {'max_depth': 40, 'max_features': 4, 'min_samp...           0.336634   \n",
      "13   {'max_depth': 40, 'max_features': 4, 'min_samp...           0.356436   \n",
      "14   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.331683   \n",
      "15   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.336634   \n",
      "16   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.336634   \n",
      "17   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.361386   \n",
      "18   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.336634   \n",
      "19   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.346535   \n",
      "20   {'max_depth': 40, 'max_features': 6, 'min_samp...           0.321782   \n",
      "21   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.301980   \n",
      "22   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.371287   \n",
      "23   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.346535   \n",
      "24   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.381188   \n",
      "25   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.351485   \n",
      "26   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.351485   \n",
      "27   {'max_depth': 40, 'max_features': 20, 'min_sam...           0.321782   \n",
      "28   {'max_depth': 40, 'max_features': 40, 'min_sam...           0.301980   \n",
      "29   {'max_depth': 40, 'max_features': 40, 'min_sam...           0.341584   \n",
      "..                                                 ...                ...   \n",
      "250  {'max_depth': 100, 'max_features': 20, 'min_sa...           0.351485   \n",
      "251  {'max_depth': 100, 'max_features': 20, 'min_sa...           0.366337   \n",
      "252  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.321782   \n",
      "253  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.301980   \n",
      "254  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.257426   \n",
      "255  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.356436   \n",
      "256  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.351485   \n",
      "257  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.262376   \n",
      "258  {'max_depth': 100, 'max_features': 40, 'min_sa...           0.415842   \n",
      "259  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.346535   \n",
      "260  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.326733   \n",
      "261  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.292079   \n",
      "262  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.297030   \n",
      "263  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.297030   \n",
      "264  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.351485   \n",
      "265  {'max_depth': 100, 'max_features': 50, 'min_sa...           0.351485   \n",
      "266  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.301980   \n",
      "267  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.331683   \n",
      "268  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.410891   \n",
      "269  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.297030   \n",
      "270  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.287129   \n",
      "271  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.346535   \n",
      "272  {'max_depth': 100, 'max_features': 80, 'min_sa...           0.371287   \n",
      "273  {'max_depth': 100, 'max_features': 100, 'min_s...           0.331683   \n",
      "274  {'max_depth': 100, 'max_features': 100, 'min_s...           0.346535   \n",
      "275  {'max_depth': 100, 'max_features': 100, 'min_s...           0.371287   \n",
      "276  {'max_depth': 100, 'max_features': 100, 'min_s...           0.316832   \n",
      "277  {'max_depth': 100, 'max_features': 100, 'min_s...           0.316832   \n",
      "278  {'max_depth': 100, 'max_features': 100, 'min_s...           0.321782   \n",
      "279  {'max_depth': 100, 'max_features': 100, 'min_s...           0.361386   \n",
      "\n",
      "     split1_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0                0.330       ...                   0.343        0.007340   \n",
      "1                0.290       ...                   0.330        0.025334   \n",
      "2                0.355       ...                   0.351        0.023957   \n",
      "3                0.345       ...                   0.341        0.014514   \n",
      "4                0.315       ...                   0.331        0.029471   \n",
      "5                0.345       ...                   0.336        0.010698   \n",
      "6                0.320       ...                   0.333        0.017177   \n",
      "7                0.355       ...                   0.366        0.007534   \n",
      "8                0.340       ...                   0.346        0.013375   \n",
      "9                0.345       ...                   0.339        0.009236   \n",
      "10               0.350       ...                   0.323        0.032073   \n",
      "11               0.370       ...                   0.341        0.037049   \n",
      "12               0.360       ...                   0.353        0.017334   \n",
      "13               0.330       ...                   0.336        0.019013   \n",
      "14               0.355       ...                   0.344        0.034499   \n",
      "15               0.325       ...                   0.323        0.010248   \n",
      "16               0.310       ...                   0.328        0.009853   \n",
      "17               0.335       ...                   0.337        0.016798   \n",
      "18               0.305       ...                   0.338        0.021390   \n",
      "19               0.350       ...                   0.340        0.009711   \n",
      "20               0.335       ...                   0.341        0.014197   \n",
      "21               0.305       ...                   0.333        0.033742   \n",
      "22               0.290       ...                   0.318        0.032373   \n",
      "23               0.350       ...                   0.338        0.032483   \n",
      "24               0.365       ...                   0.348        0.021661   \n",
      "25               0.240       ...                   0.305        0.036827   \n",
      "26               0.375       ...                   0.344        0.027542   \n",
      "27               0.265       ...                   0.303        0.020182   \n",
      "28               0.290       ...                   0.298        0.011057   \n",
      "29               0.385       ...                   0.328        0.039172   \n",
      "..                 ...       ...                     ...             ...   \n",
      "250              0.350       ...                   0.325        0.029840   \n",
      "251              0.335       ...                   0.329        0.023158   \n",
      "252              0.370       ...                   0.333        0.025119   \n",
      "253              0.395       ...                   0.327        0.035547   \n",
      "254              0.310       ...                   0.289        0.029440   \n",
      "255              0.350       ...                   0.360        0.011189   \n",
      "256              0.305       ...                   0.328        0.018625   \n",
      "257              0.345       ...                   0.323        0.033483   \n",
      "258              0.390       ...                   0.350        0.046196   \n",
      "259              0.325       ...                   0.322        0.020830   \n",
      "260              0.295       ...                   0.305        0.030597   \n",
      "261              0.375       ...                   0.309        0.036326   \n",
      "262              0.355       ...                   0.323        0.022464   \n",
      "263              0.330       ...                   0.329        0.023236   \n",
      "264              0.315       ...                   0.308        0.032501   \n",
      "265              0.355       ...                   0.336        0.019523   \n",
      "266              0.330       ...                   0.304        0.025240   \n",
      "267              0.285       ...                   0.329        0.034691   \n",
      "268              0.370       ...                   0.348        0.042566   \n",
      "269              0.380       ...                   0.294        0.047406   \n",
      "270              0.375       ...                   0.320        0.047596   \n",
      "271              0.285       ...                   0.329        0.033837   \n",
      "272              0.340       ...                   0.342        0.025430   \n",
      "273              0.315       ...                   0.327        0.023203   \n",
      "274              0.325       ...                   0.331        0.014682   \n",
      "275              0.335       ...                   0.348        0.012569   \n",
      "276              0.385       ...                   0.343        0.030392   \n",
      "277              0.275       ...                   0.320        0.032329   \n",
      "278              0.320       ...                   0.328        0.032419   \n",
      "279              0.380       ...                   0.346        0.022587   \n",
      "\n",
      "     rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                 45            0.500000             0.44750   \n",
      "1                127            0.489975             0.43375   \n",
      "2                 21            0.414787             0.40125   \n",
      "3                 57            0.406015             0.40250   \n",
      "4                121            0.419799             0.42375   \n",
      "5                 82            0.399749             0.42250   \n",
      "6                105            0.423559             0.41125   \n",
      "7                  4            0.468672             0.45750   \n",
      "8                 31            0.439850             0.42875   \n",
      "9                 66            0.451128             0.43625   \n",
      "10               178            0.474937             0.43375   \n",
      "11                57            0.468672             0.42750   \n",
      "12                15            0.468672             0.45000   \n",
      "13                82            0.433584             0.45500   \n",
      "14                40            0.489975             0.49000   \n",
      "15               178            0.481203             0.49750   \n",
      "16               143            0.426065             0.44875   \n",
      "17                79            0.434837             0.47000   \n",
      "18                71            0.443609             0.47375   \n",
      "19                63            0.439850             0.43000   \n",
      "20                57            0.458647             0.43000   \n",
      "21               105            0.624060             0.62750   \n",
      "22               203            0.577694             0.61000   \n",
      "23                71            0.515038             0.53500   \n",
      "24                24            0.563910             0.51125   \n",
      "25               259            0.556391             0.57000   \n",
      "26                40            0.546366             0.49625   \n",
      "27               264            0.469925             0.50625   \n",
      "28               270            0.674185             0.68250   \n",
      "29               143            0.654135             0.58125   \n",
      "..               ...                 ...                 ...   \n",
      "250              166            0.587719             0.64875   \n",
      "251              134            0.562657             0.55125   \n",
      "252              105            0.805764             0.79375   \n",
      "253              155            0.779449             0.73500   \n",
      "254              279            0.681704             0.66000   \n",
      "255                6            0.640351             0.61250   \n",
      "256              143            0.645363             0.67750   \n",
      "257              178            0.610276             0.62875   \n",
      "258               22            0.619048             0.60500   \n",
      "259              186            0.820802             0.81250   \n",
      "260              259            0.746867             0.71500   \n",
      "261              242            0.691729             0.70750   \n",
      "262              178            0.676692             0.61500   \n",
      "263              134            0.619048             0.64500   \n",
      "264              246            0.612782             0.57750   \n",
      "265               82            0.474937             0.50875   \n",
      "266              262            0.824561             0.81000   \n",
      "267              134            0.768170             0.73250   \n",
      "268               24            0.718045             0.67125   \n",
      "269              276            0.680451             0.63125   \n",
      "270              194            0.636591             0.65125   \n",
      "271              134            0.563910             0.57500   \n",
      "272               51            0.567669             0.54250   \n",
      "273              155            0.820802             0.81125   \n",
      "274              121            0.726817             0.76375   \n",
      "275               24            0.736842             0.70000   \n",
      "276               45            0.645363             0.64125   \n",
      "277              194            0.645363             0.61625   \n",
      "278              143            0.615288             0.61875   \n",
      "279               31            0.535088             0.57750   \n",
      "\n",
      "     split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0               0.45250             0.45000            0.408978   \n",
      "1               0.45500             0.43500            0.402743   \n",
      "2               0.41375             0.43875            0.399002   \n",
      "3               0.41625             0.41125            0.418953   \n",
      "4               0.40625             0.42500            0.413965   \n",
      "5               0.44500             0.41375            0.411471   \n",
      "6               0.39625             0.40250            0.430175   \n",
      "7               0.48250             0.45875            0.507481   \n",
      "8               0.46000             0.54875            0.471322   \n",
      "9               0.46625             0.43500            0.463840   \n",
      "10              0.46875             0.42625            0.430175   \n",
      "11              0.47250             0.42375            0.466334   \n",
      "12              0.44125             0.42375            0.413965   \n",
      "13              0.47875             0.42250            0.446384   \n",
      "14              0.49000             0.49125            0.539900   \n",
      "15              0.47375             0.48000            0.471322   \n",
      "16              0.45375             0.45750            0.452618   \n",
      "17              0.46750             0.43625            0.450125   \n",
      "18              0.44750             0.43625            0.465087   \n",
      "19              0.45250             0.46500            0.457606   \n",
      "20              0.42500             0.45500            0.427681   \n",
      "21              0.62125             0.62000            0.589776   \n",
      "22              0.55875             0.60000            0.553616   \n",
      "23              0.58750             0.57250            0.521197   \n",
      "24              0.54000             0.45500            0.522444   \n",
      "25              0.55625             0.55875            0.518703   \n",
      "26              0.52125             0.50625            0.492519   \n",
      "27              0.48875             0.46000            0.517456   \n",
      "28              0.67250             0.74625            0.617207   \n",
      "29              0.60000             0.64625            0.574813   \n",
      "..                  ...                 ...                 ...   \n",
      "250             0.62000             0.58250            0.593516   \n",
      "251             0.52250             0.57750            0.521197   \n",
      "252             0.80250             0.82125            0.825436   \n",
      "253             0.71500             0.69750            0.720698   \n",
      "254             0.67500             0.67375            0.699501   \n",
      "255             0.66375             0.68875            0.703242   \n",
      "256             0.60500             0.62875            0.619701   \n",
      "257             0.61375             0.61000            0.623441   \n",
      "258             0.59000             0.57250            0.572319   \n",
      "259             0.84750             0.82000            0.832918   \n",
      "260             0.74500             0.73000            0.709476   \n",
      "261             0.70250             0.69125            0.688279   \n",
      "262             0.67875             0.61375            0.650873   \n",
      "263             0.62500             0.64375            0.664589   \n",
      "264             0.57250             0.63375            0.629676   \n",
      "265             0.48250             0.57875            0.534913   \n",
      "266             0.82875             0.81125            0.822943   \n",
      "267             0.74750             0.73500            0.715711   \n",
      "268             0.67375             0.68750            0.692020   \n",
      "269             0.65000             0.63125            0.669576   \n",
      "270             0.65750             0.59375            0.648379   \n",
      "271             0.64625             0.58875            0.629676   \n",
      "272             0.60500             0.53625            0.537406   \n",
      "273             0.83625             0.82000            0.809227   \n",
      "274             0.75125             0.72625            0.716958   \n",
      "275             0.69750             0.71000            0.693267   \n",
      "276             0.66875             0.65125            0.620948   \n",
      "277             0.62000             0.66375            0.597257   \n",
      "278             0.61750             0.60375            0.627182   \n",
      "279             0.54875             0.58875            0.531172   \n",
      "\n",
      "     mean_train_score  std_train_score  \n",
      "0            0.451796         0.028911  \n",
      "1            0.443294         0.028707  \n",
      "2            0.413508         0.014139  \n",
      "3            0.410994         0.006131  \n",
      "4            0.417753         0.006919  \n",
      "5            0.418494         0.015112  \n",
      "6            0.412747         0.012649  \n",
      "7            0.474981         0.018556  \n",
      "8            0.469734         0.042222  \n",
      "9            0.450494         0.013189  \n",
      "10           0.446772         0.020700  \n",
      "11           0.451751         0.021455  \n",
      "12           0.439527         0.019310  \n",
      "13           0.447244         0.019248  \n",
      "14           0.500225         0.019844  \n",
      "15           0.480755         0.009157  \n",
      "16           0.447737         0.011189  \n",
      "17           0.451742         0.014900  \n",
      "18           0.453239         0.013967  \n",
      "19           0.448991         0.012546  \n",
      "20           0.439265         0.014469  \n",
      "21           0.616517         0.013617  \n",
      "22           0.580012         0.022149  \n",
      "23           0.546247         0.028702  \n",
      "24           0.518521         0.036400  \n",
      "25           0.552019         0.017410  \n",
      "26           0.512527         0.019626  \n",
      "27           0.488476         0.021498  \n",
      "28           0.678528         0.041030  \n",
      "29           0.611290         0.032919  \n",
      "..                ...              ...  \n",
      "250          0.606497         0.024757  \n",
      "251          0.547021         0.022179  \n",
      "252          0.809740         0.011855  \n",
      "253          0.729529         0.027701  \n",
      "254          0.677991         0.012861  \n",
      "255          0.661719         0.032674  \n",
      "256          0.635263         0.024845  \n",
      "257          0.617243         0.007537  \n",
      "258          0.591773         0.018286  \n",
      "259          0.826744         0.012269  \n",
      "260          0.729269         0.015186  \n",
      "261          0.696252         0.007411  \n",
      "262          0.647013         0.028405  \n",
      "263          0.639477         0.016164  \n",
      "264          0.605242         0.025722  \n",
      "265          0.515970         0.037832  \n",
      "266          0.819501         0.007501  \n",
      "267          0.739776         0.017440  \n",
      "268          0.688513         0.016742  \n",
      "269          0.652505         0.019911  \n",
      "270          0.637494         0.022901  \n",
      "271          0.600717         0.031847  \n",
      "272          0.557765         0.026228  \n",
      "273          0.819506         0.009551  \n",
      "274          0.737005         0.017548  \n",
      "275          0.707522         0.015659  \n",
      "276          0.645512         0.015457  \n",
      "277          0.628524         0.023347  \n",
      "278          0.616494         0.007539  \n",
      "279          0.556252         0.022982  \n",
      "\n",
      "[280 rows x 23 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'max_depth': 40, 'max_features': 50, 'min_samples_split': 60}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Linear SVC: \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0        0.008990      0.003031         0.001199    3.995944e-04   1e-05   \n",
      "1        0.006796      0.000747         0.000800    4.002342e-04   1e-05   \n",
      "2        0.004997      0.000633         0.000801    4.003290e-04   1e-05   \n",
      "3        0.004798      0.000748         0.001000    8.529922e-07   1e-05   \n",
      "4        0.006596      0.001356         0.001399    7.997279e-04   1e-05   \n",
      "5        0.016590      0.006883         0.001999    2.095943e-03   0.001   \n",
      "6        0.011993      0.002097         0.001002    4.062921e-06   0.001   \n",
      "7        0.008403      0.000490         0.000800    4.001619e-04   0.001   \n",
      "8        0.007596      0.002252         0.001995    2.529405e-03   0.001   \n",
      "9        0.004898      0.000655         0.000800    4.002336e-04   0.001   \n",
      "10       0.008598      0.000493         0.001000    1.038148e-06    0.01   \n",
      "11       0.009002      0.000027         0.001004    7.513780e-06    0.01   \n",
      "12       0.007596      0.000490         0.001000    1.784161e-07    0.01   \n",
      "13       0.009794      0.007115         0.001000    8.120244e-07    0.01   \n",
      "14       0.005213      0.000384         0.000800    3.999491e-04    0.01   \n",
      "15       0.025998      0.000598         0.001201    9.792872e-04       1   \n",
      "16       0.030183      0.005486         0.001000    9.246216e-07       1   \n",
      "17       0.023989      0.006862         0.001597    1.200410e-03       1   \n",
      "18       0.016388      0.001352         0.001200    3.985872e-04       1   \n",
      "19       0.007006      0.000642         0.001204    7.543039e-04       1   \n",
      "20       0.043164      0.012413         0.001010    1.149029e-05       2   \n",
      "21       0.039182      0.003541         0.000599    4.892054e-04       2   \n",
      "22       0.034284      0.012725         0.001000    8.313940e-07       2   \n",
      "23       0.018590      0.003484         0.001208    4.048905e-04       2   \n",
      "24       0.007809      0.000744         0.001794    1.161891e-03       2   \n",
      "25       0.083562      0.013016         0.001001    4.909339e-07      10   \n",
      "26       0.096148      0.019044         0.001197    7.490610e-04      10   \n",
      "27       0.058576      0.010630         0.000796    3.982885e-04      10   \n",
      "28       0.022197      0.000748         0.001001    1.435272e-06      10   \n",
      "29       0.005194      0.000745         0.000996    7.337097e-06      10   \n",
      "\n",
      "   param_tol                     params  split0_test_score  split1_test_score  \\\n",
      "0       0.01  {'C': 1e-05, 'tol': 0.01}           0.356436              0.355   \n",
      "1       0.01  {'C': 1e-05, 'tol': 0.01}           0.356436              0.355   \n",
      "2        0.1   {'C': 1e-05, 'tol': 0.1}           0.356436              0.355   \n",
      "3          1     {'C': 1e-05, 'tol': 1}           0.356436              0.355   \n",
      "4         10    {'C': 1e-05, 'tol': 10}           0.356436              0.355   \n",
      "5       0.01  {'C': 0.001, 'tol': 0.01}           0.356436              0.355   \n",
      "6       0.01  {'C': 0.001, 'tol': 0.01}           0.356436              0.355   \n",
      "7        0.1   {'C': 0.001, 'tol': 0.1}           0.356436              0.355   \n",
      "8          1     {'C': 0.001, 'tol': 1}           0.356436              0.355   \n",
      "9         10    {'C': 0.001, 'tol': 10}           0.356436              0.355   \n",
      "10      0.01   {'C': 0.01, 'tol': 0.01}           0.381188              0.390   \n",
      "11      0.01   {'C': 0.01, 'tol': 0.01}           0.381188              0.390   \n",
      "12       0.1    {'C': 0.01, 'tol': 0.1}           0.381188              0.390   \n",
      "13         1      {'C': 0.01, 'tol': 1}           0.405941              0.380   \n",
      "14        10     {'C': 0.01, 'tol': 10}           0.400990              0.425   \n",
      "15      0.01      {'C': 1, 'tol': 0.01}           0.440594              0.435   \n",
      "16      0.01      {'C': 1, 'tol': 0.01}           0.440594              0.435   \n",
      "17       0.1       {'C': 1, 'tol': 0.1}           0.440594              0.435   \n",
      "18         1         {'C': 1, 'tol': 1}           0.445545              0.455   \n",
      "19        10        {'C': 1, 'tol': 10}           0.252475              0.365   \n",
      "20      0.01      {'C': 2, 'tol': 0.01}           0.435644              0.415   \n",
      "21      0.01      {'C': 2, 'tol': 0.01}           0.430693              0.415   \n",
      "22       0.1       {'C': 2, 'tol': 0.1}           0.435644              0.420   \n",
      "23         1         {'C': 2, 'tol': 1}           0.435644              0.430   \n",
      "24        10        {'C': 2, 'tol': 10}           0.400990              0.345   \n",
      "25      0.01     {'C': 10, 'tol': 0.01}           0.425743              0.415   \n",
      "26      0.01     {'C': 10, 'tol': 0.01}           0.425743              0.415   \n",
      "27       0.1      {'C': 10, 'tol': 0.1}           0.425743              0.415   \n",
      "28         1        {'C': 10, 'tol': 1}           0.415842              0.425   \n",
      "29        10       {'C': 10, 'tol': 10}           0.351485              0.320   \n",
      "\n",
      "    split2_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0               0.355       ...                   0.356        0.001401   \n",
      "1               0.355       ...                   0.356        0.001401   \n",
      "2               0.355       ...                   0.356        0.001401   \n",
      "3               0.355       ...                   0.356        0.001401   \n",
      "4               0.355       ...                   0.356        0.001401   \n",
      "5               0.355       ...                   0.356        0.001401   \n",
      "6               0.355       ...                   0.356        0.001401   \n",
      "7               0.355       ...                   0.356        0.001401   \n",
      "8               0.355       ...                   0.356        0.001401   \n",
      "9               0.355       ...                   0.356        0.001401   \n",
      "10              0.385       ...                   0.377        0.011273   \n",
      "11              0.385       ...                   0.377        0.011273   \n",
      "12              0.385       ...                   0.377        0.011273   \n",
      "13              0.390       ...                   0.381        0.022756   \n",
      "14              0.355       ...                   0.387        0.026239   \n",
      "15              0.425       ...                   0.427        0.009668   \n",
      "16              0.425       ...                   0.427        0.009668   \n",
      "17              0.425       ...                   0.426        0.010558   \n",
      "18              0.455       ...                   0.440        0.015012   \n",
      "19              0.340       ...                   0.336        0.043010   \n",
      "20              0.435       ...                   0.422        0.013379   \n",
      "21              0.435       ...                   0.421        0.012476   \n",
      "22              0.435       ...                   0.424        0.011269   \n",
      "23              0.425       ...                   0.423        0.012206   \n",
      "24              0.335       ...                   0.363        0.024263   \n",
      "25              0.425       ...                   0.416        0.009352   \n",
      "26              0.425       ...                   0.416        0.009352   \n",
      "27              0.425       ...                   0.416        0.009352   \n",
      "28              0.440       ...                   0.418        0.013713   \n",
      "29              0.310       ...                   0.349        0.045142   \n",
      "\n",
      "    rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                19            0.355890             0.35625   \n",
      "1                19            0.355890             0.35625   \n",
      "2                19            0.355890             0.35625   \n",
      "3                19            0.355890             0.35625   \n",
      "4                19            0.355890             0.35625   \n",
      "5                19            0.355890             0.35625   \n",
      "6                19            0.355890             0.35625   \n",
      "7                19            0.355890             0.35625   \n",
      "8                19            0.355890             0.35625   \n",
      "9                19            0.355890             0.35625   \n",
      "10               15            0.418546             0.41625   \n",
      "11               15            0.418546             0.41625   \n",
      "12               15            0.418546             0.41500   \n",
      "13               14            0.452381             0.39500   \n",
      "14               13            0.473684             0.46250   \n",
      "15                2            0.957393             0.96500   \n",
      "16                2            0.957393             0.96500   \n",
      "17                4            0.957393             0.96500   \n",
      "18                1            0.944862             0.96125   \n",
      "19               30            0.428571             0.51375   \n",
      "20                7            0.989975             0.99750   \n",
      "21                8            0.989975             0.99750   \n",
      "22                5            0.989975             0.99750   \n",
      "23                6            0.981203             0.99250   \n",
      "24               18            0.500000             0.52375   \n",
      "25               10            1.000000             1.00000   \n",
      "26               10            1.000000             1.00000   \n",
      "27               10            1.000000             1.00000   \n",
      "28                9            1.000000             1.00000   \n",
      "29               29            0.578947             0.50750   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0              0.35625             0.35625            0.355362   \n",
      "1              0.35625             0.35625            0.355362   \n",
      "2              0.35625             0.35625            0.355362   \n",
      "3              0.35625             0.35625            0.355362   \n",
      "4              0.35625             0.35625            0.355362   \n",
      "5              0.35625             0.35625            0.355362   \n",
      "6              0.35625             0.35625            0.355362   \n",
      "7              0.35625             0.35625            0.355362   \n",
      "8              0.35625             0.35625            0.355362   \n",
      "9              0.35625             0.35625            0.355362   \n",
      "10             0.41500             0.41625            0.423940   \n",
      "11             0.41500             0.41625            0.423940   \n",
      "12             0.41500             0.41625            0.423940   \n",
      "13             0.41250             0.42875            0.417706   \n",
      "14             0.35750             0.38000            0.481297   \n",
      "15             0.96375             0.97000            0.955112   \n",
      "16             0.96375             0.97000            0.956359   \n",
      "17             0.96125             0.96750            0.955112   \n",
      "18             0.95750             0.96125            0.932668   \n",
      "19             0.49250             0.43250            0.458853   \n",
      "20             0.99500             0.99500            0.993766   \n",
      "21             0.99500             0.99500            0.993766   \n",
      "22             0.99375             0.99375            0.993766   \n",
      "23             0.98250             0.98500            0.986284   \n",
      "24             0.53875             0.56375            0.556110   \n",
      "25             1.00000             1.00000            1.000000   \n",
      "26             1.00000             1.00000            1.000000   \n",
      "27             1.00000             1.00000            1.000000   \n",
      "28             1.00000             1.00000            1.000000   \n",
      "29             0.42875             0.59375            0.406484   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.356000         0.000348  \n",
      "1           0.356000         0.000348  \n",
      "2           0.356000         0.000348  \n",
      "3           0.356000         0.000348  \n",
      "4           0.356000         0.000348  \n",
      "5           0.356000         0.000348  \n",
      "6           0.356000         0.000348  \n",
      "7           0.356000         0.000348  \n",
      "8           0.356000         0.000348  \n",
      "9           0.356000         0.000348  \n",
      "10          0.417997         0.003185  \n",
      "11          0.417997         0.003185  \n",
      "12          0.417747         0.003356  \n",
      "13          0.421267         0.018992  \n",
      "14          0.430996         0.051667  \n",
      "15          0.962251         0.005374  \n",
      "16          0.962501         0.005057  \n",
      "17          0.961251         0.004597  \n",
      "18          0.951506         0.011179  \n",
      "19          0.465235         0.033328  \n",
      "20          0.994248         0.002458  \n",
      "21          0.994248         0.002458  \n",
      "22          0.993748         0.002380  \n",
      "23          0.985497         0.003933  \n",
      "24          0.536472         0.022921  \n",
      "25          1.000000         0.000000  \n",
      "26          1.000000         0.000000  \n",
      "27          1.000000         0.000000  \n",
      "28          1.000000         0.000000  \n",
      "29          0.503086         0.075963  \n",
      "\n",
      "[30 rows x 22 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'C': 1, 'tol': 1}\n"
     ]
    }
   ],
   "source": [
    "parametersDTC = {'max_depth': [40, 60, 80, 90, 100], 'min_samples_split': [10, 20, 30, 40, 50, 60, 100], \"max_features\": [1, 4, 6, 20, 40, 50, 80, 100]}\n",
    "get_DecisionTreesParams(Yelp_FBOW['valid'][0],Yelp_FBOW['valid'][1], parametersDTC)\n",
    "print('\\n')\n",
    "\n",
    "parametersSVC = {'tol': [0.01, 0.01, 0.1, 1, 10], 'C': [0.00001, 0.001, 0.01, 1, 2, 10]}\n",
    "get_SVCParams(Yelp_FBOW['valid'][0],Yelp_FBOW['valid'][1], parametersSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores for train set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "66.42857142857143\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 100 100 50\n",
      "63.67142857142857\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 1 0.1\n",
      "82.05714285714286\n",
      "\n",
      "\n",
      "F1-scores for valid set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "93.5\n",
      "\n",
      "\n",
      "F1-scores for valid set\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 100 100 50\n",
      "67.30000000000001\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 1 0.1\n",
      "96.0\n",
      "\n",
      "\n",
      "F1-scores for test set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "80.652\n",
      "\n",
      "\n",
      "F1-scores for test set\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 100 100 50\n",
      "86.64\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 1 0.1\n",
      "91.816\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1-scores for train set\\n')\n",
    "calculate_GaussianNB((Yelp_BBOW['train'][0]).toarray(), Yelp_BBOW['train'][1])\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(Yelp_FBOW['train'][0], Yelp_FBOW['train'][1], 100,100,50 )\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_FBOW['train'][0], Yelp_FBOW['train'][1], 1, 0.1)\n",
    "print('\\n')\n",
    "print('F1-scores for valid set\\n')\n",
    "calculate_GaussianNB((Yelp_BBOW['valid'][0]).toarray(), Yelp_BBOW['valid'][1])\n",
    "print('\\n')\n",
    "print('F1-scores for valid set\\n')\n",
    "calculate_DecisionTrees(Yelp_FBOW['valid'][0], Yelp_FBOW['valid'][1], 100, 100, 50)\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_FBOW['valid'][0], Yelp_FBOW['valid'][1], 1, 0.1)\n",
    "print('\\n')\n",
    "print('F1-scores for test set\\n')\n",
    "calculate_GaussianNB((Yelp_FBOW['test'][0]).toarray(), Yelp_FBOW['test'][1] )\n",
    "print('\\n')\n",
    "print('F1-scores for test set\\n')\n",
    "calculate_DecisionTrees(Yelp_FBOW['test'][0], Yelp_FBOW['test'][1], 100, 100, 50)\n",
    "print('\\n')\n",
    "calculate_SVC(Yelp_FBOW['test'][0], Yelp_FBOW['test'][1],1, 0.1)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for random and majority class classifier\n",
      "49.97268497933066 33.33333333333333\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramsha\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Bernoulli Naive Bayes: \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
      "0       0.050985      0.029030         0.008052    6.411677e-04       1e-07   \n",
      "1       0.039577      0.006339         0.008008    1.674781e-03       1e-05   \n",
      "2       0.035376      0.002333         0.006001    6.773102e-06      0.0001   \n",
      "3       0.033981      0.000625         0.005996    9.047349e-07       0.001   \n",
      "4       0.039776      0.005561         0.007197    1.719786e-03        0.01   \n",
      "5       0.036975      0.003689         0.007396    1.019786e-03         0.1   \n",
      "6       0.038976      0.006599         0.007605    1.197520e-03           1   \n",
      "7       0.034180      0.000399         0.005597    4.900408e-04          10   \n",
      "8       0.033179      0.000399         0.006001    7.491960e-06          20   \n",
      "9       0.034376      0.000798         0.006198    9.792588e-04          30   \n",
      "\n",
      "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0   {'alpha': 1e-07}             0.8400             0.8345             0.8420   \n",
      "1   {'alpha': 1e-05}             0.8440             0.8370             0.8455   \n",
      "2  {'alpha': 0.0001}             0.8465             0.8405             0.8475   \n",
      "3   {'alpha': 0.001}             0.8505             0.8420             0.8505   \n",
      "4    {'alpha': 0.01}             0.8525             0.8425             0.8535   \n",
      "5     {'alpha': 0.1}             0.8565             0.8425             0.8510   \n",
      "6       {'alpha': 1}             0.8605             0.8455             0.8525   \n",
      "7      {'alpha': 10}             0.8560             0.8460             0.8475   \n",
      "8      {'alpha': 20}             0.8555             0.8420             0.8465   \n",
      "9      {'alpha': 30}             0.8510             0.8365             0.8425   \n",
      "\n",
      "   split3_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0             0.8325       ...                  0.8327        0.009740   \n",
      "1             0.8385       ...                  0.8363        0.010405   \n",
      "2             0.8415       ...                  0.8389        0.010557   \n",
      "3             0.8445       ...                  0.8414        0.011447   \n",
      "4             0.8490       ...                  0.8438        0.011797   \n",
      "5             0.8500       ...                  0.8458        0.009511   \n",
      "6             0.8440       ...                  0.8467        0.009791   \n",
      "7             0.8415       ...                  0.8442        0.008512   \n",
      "8             0.8375       ...                  0.8414        0.009932   \n",
      "9             0.8325       ...                  0.8363        0.010661   \n",
      "\n",
      "   rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0               10            0.902625            0.901000   \n",
      "1                8            0.902375            0.900500   \n",
      "2                7            0.901875            0.900250   \n",
      "3                5            0.901375            0.899625   \n",
      "4                4            0.900750            0.899000   \n",
      "5                2            0.898875            0.897125   \n",
      "6                1            0.894375            0.892750   \n",
      "7                3            0.879250            0.877375   \n",
      "8                5            0.871375            0.869250   \n",
      "9                8            0.866500            0.862750   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0            0.902250            0.903625            0.896500   \n",
      "1            0.901875            0.903000            0.896375   \n",
      "2            0.901375            0.902500            0.896000   \n",
      "3            0.901125            0.902000            0.895500   \n",
      "4            0.900500            0.901125            0.894375   \n",
      "5            0.898875            0.899250            0.892500   \n",
      "6            0.894625            0.894875            0.887125   \n",
      "7            0.878625            0.879125            0.870250   \n",
      "8            0.872875            0.871125            0.858625   \n",
      "9            0.868000            0.866000            0.850125   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          0.901200         0.002496  \n",
      "1          0.900825         0.002372  \n",
      "2          0.900400         0.002320  \n",
      "3          0.899925         0.002346  \n",
      "4          0.899150         0.002494  \n",
      "5          0.897325         0.002523  \n",
      "6          0.892750         0.002909  \n",
      "7          0.876925         0.003403  \n",
      "8          0.868650         0.005143  \n",
      "9          0.862675         0.006505  \n",
      "\n",
      "[10 rows x 21 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'alpha': 1}\n",
      "\n",
      "\n",
      "The performance of hyperparameters in Decision Tree: \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.147515      0.017750         0.008802        0.001826   \n",
      "1        0.159309      0.027823         0.009195        0.001168   \n",
      "2        0.167103      0.029325         0.008604        0.001356   \n",
      "3        0.159109      0.031718         0.009195        0.001469   \n",
      "4        0.167308      0.041365         0.008202        0.000397   \n",
      "5        0.298828      0.053418         0.015595        0.015189   \n",
      "6        0.384780      0.192225         0.009795        0.001468   \n",
      "7        0.299432      0.072880         0.009401        0.001198   \n",
      "8        0.249258      0.042654         0.009398        0.001494   \n",
      "9        0.222872      0.025598         0.008403        0.000485   \n",
      "10       0.362792      0.049530         0.008606        0.001736   \n",
      "11       0.355200      0.015726         0.008999        0.000894   \n",
      "12       0.329415      0.041543         0.007997        0.000631   \n",
      "13       0.350995      0.041709         0.008403        0.000484   \n",
      "14       0.360196      0.035807         0.011198        0.003540   \n",
      "15       0.489315      0.022687         0.008399        0.000488   \n",
      "16       0.480027      0.080189         0.009796        0.002710   \n",
      "17       0.423156      0.050814         0.007811        0.000398   \n",
      "18       0.465933      0.053960         0.008207        0.000402   \n",
      "19       0.475927      0.046533         0.008999        0.001101   \n",
      "20       0.234662      0.028480         0.008599        0.001198   \n",
      "21       0.194692      0.018069         0.008403        0.000805   \n",
      "22       0.196287      0.030290         0.008600        0.000797   \n",
      "23       0.188293      0.042376         0.008195        0.000399   \n",
      "24       0.187696      0.033835         0.008602        0.001202   \n",
      "25       0.327012      0.028418         0.008004        0.000009   \n",
      "26       0.335203      0.024935         0.007807        0.000396   \n",
      "27       0.350802      0.037983         0.008004        0.000015   \n",
      "28       0.312021      0.045005         0.008404        0.000484   \n",
      "29       0.331809      0.047085         0.008406        0.000488   \n",
      "..            ...           ...              ...             ...   \n",
      "70       0.764960      0.095412         0.010198        0.001934   \n",
      "71       1.059396      0.364063         0.011400        0.003926   \n",
      "72       0.719784      0.037387         0.008598        0.000486   \n",
      "73       0.732979      0.041422         0.008004        0.000009   \n",
      "74       0.636032      0.028642         0.008396        0.000800   \n",
      "75       0.976247      0.096022         0.008995        0.001095   \n",
      "76       0.977438      0.078611         0.008001        0.000008   \n",
      "77       0.962851      0.110473         0.008200        0.000398   \n",
      "78       0.873298      0.066033         0.009206        0.001465   \n",
      "79       0.836919      0.053521         0.008010        0.000007   \n",
      "80       0.392579      0.017328         0.007996        0.000002   \n",
      "81       0.394167      0.024998         0.008207        0.000394   \n",
      "82       0.472129      0.092278         0.008796        0.000747   \n",
      "83       0.358598      0.024193         0.008200        0.000397   \n",
      "84       0.373582      0.035978         0.008010        0.000008   \n",
      "85       0.716382      0.064632         0.008796        0.001158   \n",
      "86       0.682811      0.050718         0.009203        0.002395   \n",
      "87       0.670613      0.043771         0.008609        0.000792   \n",
      "88       0.677810      0.051949         0.008408        0.000794   \n",
      "89       0.645228      0.037361         0.008004        0.000008   \n",
      "90       0.956051      0.041084         0.008800        0.001165   \n",
      "91       0.867904      0.042943         0.008006        0.000628   \n",
      "92       0.910078      0.053864         0.008796        0.002134   \n",
      "93       0.863309      0.023210         0.008006        0.000009   \n",
      "94       0.874698      0.086952         0.008203        0.000396   \n",
      "95       1.336832      0.096715         0.009410        0.002323   \n",
      "96       2.062216      0.461901         0.010794        0.001720   \n",
      "97       1.150140      0.031199         0.008011        0.000007   \n",
      "98       1.151339      0.030898         0.008202        0.000397   \n",
      "99       1.051389      0.046762         0.008206        0.000743   \n",
      "\n",
      "   param_max_depth param_max_features param_min_samples_split  \\\n",
      "0               10               1000                       2   \n",
      "1               10               1000                       4   \n",
      "2               10               1000                       6   \n",
      "3               10               1000                       8   \n",
      "4               10               1000                      10   \n",
      "5               10               2000                       2   \n",
      "6               10               2000                       4   \n",
      "7               10               2000                       6   \n",
      "8               10               2000                       8   \n",
      "9               10               2000                      10   \n",
      "10              10               3000                       2   \n",
      "11              10               3000                       4   \n",
      "12              10               3000                       6   \n",
      "13              10               3000                       8   \n",
      "14              10               3000                      10   \n",
      "15              10               4000                       2   \n",
      "16              10               4000                       4   \n",
      "17              10               4000                       6   \n",
      "18              10               4000                       8   \n",
      "19              10               4000                      10   \n",
      "20              12               1000                       2   \n",
      "21              12               1000                       4   \n",
      "22              12               1000                       6   \n",
      "23              12               1000                       8   \n",
      "24              12               1000                      10   \n",
      "25              12               2000                       2   \n",
      "26              12               2000                       4   \n",
      "27              12               2000                       6   \n",
      "28              12               2000                       8   \n",
      "29              12               2000                      10   \n",
      "..             ...                ...                     ...   \n",
      "70              16               3000                       2   \n",
      "71              16               3000                       4   \n",
      "72              16               3000                       6   \n",
      "73              16               3000                       8   \n",
      "74              16               3000                      10   \n",
      "75              16               4000                       2   \n",
      "76              16               4000                       4   \n",
      "77              16               4000                       6   \n",
      "78              16               4000                       8   \n",
      "79              16               4000                      10   \n",
      "80              20               1000                       2   \n",
      "81              20               1000                       4   \n",
      "82              20               1000                       6   \n",
      "83              20               1000                       8   \n",
      "84              20               1000                      10   \n",
      "85              20               2000                       2   \n",
      "86              20               2000                       4   \n",
      "87              20               2000                       6   \n",
      "88              20               2000                       8   \n",
      "89              20               2000                      10   \n",
      "90              20               3000                       2   \n",
      "91              20               3000                       4   \n",
      "92              20               3000                       6   \n",
      "93              20               3000                       8   \n",
      "94              20               3000                      10   \n",
      "95              20               4000                       2   \n",
      "96              20               4000                       4   \n",
      "97              20               4000                       6   \n",
      "98              20               4000                       8   \n",
      "99              20               4000                      10   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'max_depth': 10, 'max_features': 1000, 'min_s...             0.7040   \n",
      "1   {'max_depth': 10, 'max_features': 1000, 'min_s...             0.6830   \n",
      "2   {'max_depth': 10, 'max_features': 1000, 'min_s...             0.7020   \n",
      "3   {'max_depth': 10, 'max_features': 1000, 'min_s...             0.6555   \n",
      "4   {'max_depth': 10, 'max_features': 1000, 'min_s...             0.6575   \n",
      "5   {'max_depth': 10, 'max_features': 2000, 'min_s...             0.7015   \n",
      "6   {'max_depth': 10, 'max_features': 2000, 'min_s...             0.7160   \n",
      "7   {'max_depth': 10, 'max_features': 2000, 'min_s...             0.6950   \n",
      "8   {'max_depth': 10, 'max_features': 2000, 'min_s...             0.7075   \n",
      "9   {'max_depth': 10, 'max_features': 2000, 'min_s...             0.7175   \n",
      "10  {'max_depth': 10, 'max_features': 3000, 'min_s...             0.7080   \n",
      "11  {'max_depth': 10, 'max_features': 3000, 'min_s...             0.7170   \n",
      "12  {'max_depth': 10, 'max_features': 3000, 'min_s...             0.7135   \n",
      "13  {'max_depth': 10, 'max_features': 3000, 'min_s...             0.6855   \n",
      "14  {'max_depth': 10, 'max_features': 3000, 'min_s...             0.7070   \n",
      "15  {'max_depth': 10, 'max_features': 4000, 'min_s...             0.7135   \n",
      "16  {'max_depth': 10, 'max_features': 4000, 'min_s...             0.7200   \n",
      "17  {'max_depth': 10, 'max_features': 4000, 'min_s...             0.7150   \n",
      "18  {'max_depth': 10, 'max_features': 4000, 'min_s...             0.7175   \n",
      "19  {'max_depth': 10, 'max_features': 4000, 'min_s...             0.7035   \n",
      "20  {'max_depth': 12, 'max_features': 1000, 'min_s...             0.6910   \n",
      "21  {'max_depth': 12, 'max_features': 1000, 'min_s...             0.6730   \n",
      "22  {'max_depth': 12, 'max_features': 1000, 'min_s...             0.6995   \n",
      "23  {'max_depth': 12, 'max_features': 1000, 'min_s...             0.6640   \n",
      "24  {'max_depth': 12, 'max_features': 1000, 'min_s...             0.6570   \n",
      "25  {'max_depth': 12, 'max_features': 2000, 'min_s...             0.7275   \n",
      "26  {'max_depth': 12, 'max_features': 2000, 'min_s...             0.7095   \n",
      "27  {'max_depth': 12, 'max_features': 2000, 'min_s...             0.6955   \n",
      "28  {'max_depth': 12, 'max_features': 2000, 'min_s...             0.6940   \n",
      "29  {'max_depth': 12, 'max_features': 2000, 'min_s...             0.6930   \n",
      "..                                                ...                ...   \n",
      "70  {'max_depth': 16, 'max_features': 3000, 'min_s...             0.7095   \n",
      "71  {'max_depth': 16, 'max_features': 3000, 'min_s...             0.7220   \n",
      "72  {'max_depth': 16, 'max_features': 3000, 'min_s...             0.7100   \n",
      "73  {'max_depth': 16, 'max_features': 3000, 'min_s...             0.6955   \n",
      "74  {'max_depth': 16, 'max_features': 3000, 'min_s...             0.7120   \n",
      "75  {'max_depth': 16, 'max_features': 4000, 'min_s...             0.7085   \n",
      "76  {'max_depth': 16, 'max_features': 4000, 'min_s...             0.7075   \n",
      "77  {'max_depth': 16, 'max_features': 4000, 'min_s...             0.7050   \n",
      "78  {'max_depth': 16, 'max_features': 4000, 'min_s...             0.7275   \n",
      "79  {'max_depth': 16, 'max_features': 4000, 'min_s...             0.6980   \n",
      "80  {'max_depth': 20, 'max_features': 1000, 'min_s...             0.7255   \n",
      "81  {'max_depth': 20, 'max_features': 1000, 'min_s...             0.7010   \n",
      "82  {'max_depth': 20, 'max_features': 1000, 'min_s...             0.6850   \n",
      "83  {'max_depth': 20, 'max_features': 1000, 'min_s...             0.7265   \n",
      "84  {'max_depth': 20, 'max_features': 1000, 'min_s...             0.6970   \n",
      "85  {'max_depth': 20, 'max_features': 2000, 'min_s...             0.7060   \n",
      "86  {'max_depth': 20, 'max_features': 2000, 'min_s...             0.7120   \n",
      "87  {'max_depth': 20, 'max_features': 2000, 'min_s...             0.7065   \n",
      "88  {'max_depth': 20, 'max_features': 2000, 'min_s...             0.6980   \n",
      "89  {'max_depth': 20, 'max_features': 2000, 'min_s...             0.6915   \n",
      "90  {'max_depth': 20, 'max_features': 3000, 'min_s...             0.7080   \n",
      "91  {'max_depth': 20, 'max_features': 3000, 'min_s...             0.7075   \n",
      "92  {'max_depth': 20, 'max_features': 3000, 'min_s...             0.6960   \n",
      "93  {'max_depth': 20, 'max_features': 3000, 'min_s...             0.7020   \n",
      "94  {'max_depth': 20, 'max_features': 3000, 'min_s...             0.7135   \n",
      "95  {'max_depth': 20, 'max_features': 4000, 'min_s...             0.7115   \n",
      "96  {'max_depth': 20, 'max_features': 4000, 'min_s...             0.7120   \n",
      "97  {'max_depth': 20, 'max_features': 4000, 'min_s...             0.7155   \n",
      "98  {'max_depth': 20, 'max_features': 4000, 'min_s...             0.7120   \n",
      "99  {'max_depth': 20, 'max_features': 4000, 'min_s...             0.7200   \n",
      "\n",
      "    split1_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0              0.6680       ...                  0.6900        0.012345   \n",
      "1              0.6900       ...                  0.6772        0.012019   \n",
      "2              0.6530       ...                  0.6776        0.016719   \n",
      "3              0.6775       ...                  0.6762        0.022805   \n",
      "4              0.6920       ...                  0.6845        0.013649   \n",
      "5              0.7065       ...                  0.7045        0.003633   \n",
      "6              0.6900       ...                  0.7087        0.010562   \n",
      "7              0.7165       ...                  0.7039        0.012269   \n",
      "8              0.7035       ...                  0.6931        0.012439   \n",
      "9              0.7165       ...                  0.7047        0.010491   \n",
      "10             0.7070       ...                  0.7078        0.003356   \n",
      "11             0.7095       ...                  0.7126        0.003292   \n",
      "12             0.7060       ...                  0.7094        0.003216   \n",
      "13             0.6920       ...                  0.6987        0.011952   \n",
      "14             0.7135       ...                  0.7091        0.003484   \n",
      "15             0.7160       ...                  0.7112        0.004238   \n",
      "16             0.7050       ...                  0.7081        0.007800   \n",
      "17             0.7065       ...                  0.7073        0.005474   \n",
      "18             0.7135       ...                  0.7129        0.003555   \n",
      "19             0.6985       ...                  0.7036        0.004152   \n",
      "20             0.7065       ...                  0.6921        0.015529   \n",
      "21             0.7075       ...                  0.6987        0.013254   \n",
      "22             0.7315       ...                  0.6965        0.020000   \n",
      "23             0.7070       ...                  0.6918        0.017328   \n",
      "24             0.6955       ...                  0.6798        0.015709   \n",
      "25             0.7260       ...                  0.7102        0.014052   \n",
      "26             0.7155       ...                  0.7084        0.008002   \n",
      "27             0.7140       ...                  0.7051        0.006160   \n",
      "28             0.6940       ...                  0.6977        0.006416   \n",
      "29             0.7055       ...                  0.7057        0.010112   \n",
      "..                ...       ...                     ...             ...   \n",
      "70             0.7240       ...                  0.7083        0.009341   \n",
      "71             0.7080       ...                  0.7184        0.007172   \n",
      "72             0.7065       ...                  0.7077        0.002272   \n",
      "73             0.7160       ...                  0.7032        0.007814   \n",
      "74             0.7240       ...                  0.7098        0.009933   \n",
      "75             0.7095       ...                  0.7049        0.009399   \n",
      "76             0.7210       ...                  0.7115        0.007007   \n",
      "77             0.7165       ...                  0.7057        0.006439   \n",
      "78             0.7330       ...                  0.7200        0.012570   \n",
      "79             0.7200       ...                  0.7111        0.007552   \n",
      "80             0.6825       ...                  0.6993        0.015613   \n",
      "81             0.6985       ...                  0.6977        0.002657   \n",
      "82             0.7255       ...                  0.7008        0.017497   \n",
      "83             0.6960       ...                  0.6965        0.020345   \n",
      "84             0.6985       ...                  0.6979        0.009891   \n",
      "85             0.7140       ...                  0.7007        0.009532   \n",
      "86             0.6985       ...                  0.7090        0.007537   \n",
      "87             0.7205       ...                  0.7039        0.009107   \n",
      "88             0.7065       ...                  0.6991        0.009604   \n",
      "89             0.7170       ...                  0.7035        0.010090   \n",
      "90             0.7140       ...                  0.7087        0.006765   \n",
      "91             0.7115       ...                  0.7141        0.008754   \n",
      "92             0.7090       ...                  0.7027        0.004792   \n",
      "93             0.7105       ...                  0.7071        0.004684   \n",
      "94             0.7155       ...                  0.7096        0.006053   \n",
      "95             0.7295       ...                  0.7147        0.008959   \n",
      "96             0.7020       ...                  0.7047        0.004643   \n",
      "97             0.7285       ...                  0.7118        0.009621   \n",
      "98             0.7140       ...                  0.7119        0.005731   \n",
      "99             0.7245       ...                  0.7167        0.006282   \n",
      "\n",
      "    rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                93            0.742750            0.698125   \n",
      "1                99            0.757000            0.716625   \n",
      "2                98            0.758750            0.692125   \n",
      "3               100            0.703250            0.742125   \n",
      "4                96            0.738000            0.732500   \n",
      "5                65            0.747000            0.756625   \n",
      "6                39            0.777500            0.755625   \n",
      "7                66            0.769000            0.762875   \n",
      "8                90            0.754375            0.763875   \n",
      "9                63            0.754125            0.757625   \n",
      "10               46            0.766375            0.770250   \n",
      "11               18            0.768250            0.760750   \n",
      "12               34            0.772375            0.758250   \n",
      "13               78            0.766750            0.768875   \n",
      "14               36            0.763500            0.759500   \n",
      "15               23            0.771750            0.773250   \n",
      "16               44            0.774500            0.768500   \n",
      "17               52            0.772375            0.763250   \n",
      "18               16            0.771750            0.766500   \n",
      "19               68            0.760625            0.766625   \n",
      "20               91            0.769000            0.772000   \n",
      "21               78            0.747875            0.765375   \n",
      "22               86            0.766375            0.757750   \n",
      "23               92            0.721000            0.773375   \n",
      "24               97            0.737875            0.762750   \n",
      "25               28            0.781250            0.774125   \n",
      "26               41            0.793000            0.786750   \n",
      "27               60            0.796000            0.789625   \n",
      "28               82            0.789250            0.750625   \n",
      "29               57            0.780250            0.788625   \n",
      "..              ...                 ...                 ...   \n",
      "70               42            0.831000            0.843125   \n",
      "71                2            0.842500            0.837375   \n",
      "72               47            0.827875            0.839500   \n",
      "73               70            0.844625            0.839250   \n",
      "74               30            0.824750            0.836500   \n",
      "75               61            0.851250            0.841750   \n",
      "76               22            0.860750            0.852625   \n",
      "77               57            0.865750            0.844375   \n",
      "78                1            0.834125            0.844375   \n",
      "79               25            0.848000            0.834250   \n",
      "80               76            0.850250            0.856875   \n",
      "81               82            0.857625            0.863625   \n",
      "82               74            0.869875            0.842750   \n",
      "83               86            0.838875            0.852875   \n",
      "84               80            0.832625            0.857625   \n",
      "85               75            0.881000            0.858250   \n",
      "86               37            0.867625            0.883250   \n",
      "87               66            0.869125            0.857000   \n",
      "88               77            0.865000            0.856000   \n",
      "89               69            0.842750            0.859875   \n",
      "90               39            0.877750            0.876375   \n",
      "91               12            0.877750            0.861875   \n",
      "92               73            0.876375            0.866750   \n",
      "93               53            0.867500            0.874750   \n",
      "94               33            0.853000            0.862750   \n",
      "95               11            0.875500            0.880375   \n",
      "96               63            0.883875            0.876750   \n",
      "97               21            0.871250            0.874000   \n",
      "98               20            0.887125            0.876000   \n",
      "99                4            0.876750            0.864125   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0             0.757750            0.755375            0.715625   \n",
      "1             0.733500            0.743750            0.713750   \n",
      "2             0.741125            0.751625            0.745000   \n",
      "3             0.736125            0.756750            0.691250   \n",
      "4             0.737250            0.753125            0.734375   \n",
      "5             0.741875            0.768000            0.750250   \n",
      "6             0.762750            0.757125            0.762250   \n",
      "7             0.745750            0.761625            0.768625   \n",
      "8             0.739500            0.726875            0.717750   \n",
      "9             0.757125            0.759000            0.734625   \n",
      "10            0.777375            0.769000            0.761500   \n",
      "11            0.763250            0.771500            0.766125   \n",
      "12            0.764875            0.782875            0.755125   \n",
      "13            0.752375            0.773000            0.767750   \n",
      "14            0.765500            0.759000            0.754375   \n",
      "15            0.777500            0.779125            0.775000   \n",
      "16            0.768125            0.773125            0.767875   \n",
      "17            0.755000            0.770625            0.782375   \n",
      "18            0.766750            0.779875            0.762875   \n",
      "19            0.758000            0.770875            0.764375   \n",
      "20            0.781000            0.764875            0.775250   \n",
      "21            0.767875            0.773625            0.789125   \n",
      "22            0.774000            0.772125            0.764375   \n",
      "23            0.763250            0.752375            0.746000   \n",
      "24            0.768375            0.718750            0.769750   \n",
      "25            0.784000            0.787000            0.784000   \n",
      "26            0.788750            0.798000            0.792250   \n",
      "27            0.793625            0.792250            0.793000   \n",
      "28            0.792625            0.778625            0.782625   \n",
      "29            0.761625            0.790000            0.780125   \n",
      "..                 ...                 ...                 ...   \n",
      "70            0.837000            0.847000            0.842625   \n",
      "71            0.839500            0.861125            0.832250   \n",
      "72            0.836375            0.843625            0.841875   \n",
      "73            0.835250            0.850125            0.846750   \n",
      "74            0.828750            0.829375            0.834000   \n",
      "75            0.860125            0.846000            0.848375   \n",
      "76            0.846625            0.849250            0.850500   \n",
      "77            0.840250            0.839750            0.845750   \n",
      "78            0.847375            0.841125            0.837625   \n",
      "79            0.835875            0.848625            0.839500   \n",
      "80            0.862875            0.861250            0.869625   \n",
      "81            0.868250            0.851625            0.855375   \n",
      "82            0.850250            0.874000            0.852125   \n",
      "83            0.850750            0.830875            0.853875   \n",
      "84            0.845125            0.859250            0.834625   \n",
      "85            0.886250            0.882500            0.886000   \n",
      "86            0.874125            0.868375            0.869625   \n",
      "87            0.884375            0.868000            0.872875   \n",
      "88            0.871875            0.861750            0.871625   \n",
      "89            0.865125            0.874875            0.866500   \n",
      "90            0.878875            0.874750            0.876250   \n",
      "91            0.870500            0.866750            0.877000   \n",
      "92            0.875250            0.881750            0.875000   \n",
      "93            0.865875            0.869000            0.864375   \n",
      "94            0.874750            0.866250            0.866500   \n",
      "95            0.894875            0.878500            0.886375   \n",
      "96            0.883750            0.875250            0.892000   \n",
      "97            0.873500            0.874250            0.884000   \n",
      "98            0.875250            0.875500            0.881250   \n",
      "99            0.868625            0.868375            0.870375   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.733925         0.023333  \n",
      "1           0.732925         0.016312  \n",
      "2           0.737725         0.023576  \n",
      "3           0.725900         0.024630  \n",
      "4           0.739050         0.007310  \n",
      "5           0.752750         0.009002  \n",
      "6           0.763050         0.007743  \n",
      "7           0.761575         0.008449  \n",
      "8           0.740475         0.016989  \n",
      "9           0.752500         0.009078  \n",
      "10          0.768900         0.005192  \n",
      "11          0.765975         0.003754  \n",
      "12          0.766700         0.010025  \n",
      "13          0.765750         0.007017  \n",
      "14          0.760375         0.003865  \n",
      "15          0.775325         0.002697  \n",
      "16          0.770425         0.002807  \n",
      "17          0.768725         0.009183  \n",
      "18          0.769550         0.005885  \n",
      "19          0.764100         0.004509  \n",
      "20          0.772425         0.005485  \n",
      "21          0.768775         0.013318  \n",
      "22          0.766925         0.005798  \n",
      "23          0.751200         0.017762  \n",
      "24          0.751500         0.020013  \n",
      "25          0.782075         0.004371  \n",
      "26          0.791750         0.003870  \n",
      "27          0.792900         0.002064  \n",
      "28          0.778750         0.014892  \n",
      "29          0.780125         0.010120  \n",
      "..               ...              ...  \n",
      "70          0.840150         0.005578  \n",
      "71          0.842550         0.009871  \n",
      "72          0.837850         0.005549  \n",
      "73          0.843200         0.005318  \n",
      "74          0.830675         0.004135  \n",
      "75          0.849500         0.006157  \n",
      "76          0.851950         0.004809  \n",
      "77          0.847175         0.009571  \n",
      "78          0.840925         0.004705  \n",
      "79          0.841250         0.006015  \n",
      "80          0.860175         0.006437  \n",
      "81          0.859300         0.005932  \n",
      "82          0.857800         0.012033  \n",
      "83          0.845450         0.009054  \n",
      "84          0.845850         0.011132  \n",
      "85          0.878800         0.010471  \n",
      "86          0.872600         0.005783  \n",
      "87          0.870275         0.008812  \n",
      "88          0.865250         0.006040  \n",
      "89          0.861825         0.010684  \n",
      "90          0.876800         0.001407  \n",
      "91          0.870775         0.006048  \n",
      "92          0.875025         0.004808  \n",
      "93          0.868300         0.003578  \n",
      "94          0.864650         0.007033  \n",
      "95          0.883125         0.006866  \n",
      "96          0.882325         0.005986  \n",
      "97          0.875400         0.004429  \n",
      "98          0.879025         0.004613  \n",
      "99          0.869650         0.004102  \n",
      "\n",
      "[100 rows x 23 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'max_depth': 16, 'max_features': 4000, 'min_samples_split': 8}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Linear SVC: \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0        0.095745      0.006334         0.002400    4.897658e-04   1e-05   \n",
      "1        0.088953      0.003946         0.002799    3.993827e-04   1e-05   \n",
      "2        0.084552      0.010027         0.003202    1.937087e-03   1e-05   \n",
      "3        0.066763      0.006174         0.002998    1.094893e-03   1e-05   \n",
      "4        0.059163      0.002716         0.002199    3.998547e-04   1e-05   \n",
      "5        0.112536      0.009473         0.003004    1.095604e-03   0.001   \n",
      "6        0.104540      0.014199         0.002598    4.895324e-04   0.001   \n",
      "7        0.083952      0.000633         0.002802    4.018987e-04   0.001   \n",
      "8        0.072558      0.003609         0.002400    4.895318e-04   0.001   \n",
      "9        0.057166      0.000980         0.002399    4.896681e-04   0.001   \n",
      "10       0.146512      0.002249         0.002799    3.994708e-04    0.01   \n",
      "11       0.138120      0.001165         0.002200    4.003767e-04    0.01   \n",
      "12       0.107739      0.001719         0.003003    6.022889e-06    0.01   \n",
      "13       0.088549      0.012994         0.002802    4.011862e-04    0.01   \n",
      "14       0.060769      0.002310         0.002599    4.899250e-04    0.01   \n",
      "15       1.311446      0.411929         0.003002    7.479811e-06       1   \n",
      "16       1.022414      0.412706         0.002404    4.942970e-04       1   \n",
      "17       0.239059      0.020842         0.002604    4.923413e-04       1   \n",
      "18       0.116930      0.003285         0.002203    4.053121e-04       1   \n",
      "19       0.058567      0.001624         0.002999    1.018246e-06       1   \n",
      "20       1.391801      0.396843         0.002999    1.118282e-06       2   \n",
      "21       1.264474      0.401067         0.002399    4.891617e-04       2   \n",
      "22       0.247657      0.013719         0.002599    4.891231e-04       2   \n",
      "23       0.115334      0.004268         0.002199    3.994960e-04       2   \n",
      "24       0.064167      0.005980         0.002596    4.866189e-04       2   \n",
      "25       1.363618      0.382075         0.002799    7.476148e-04      10   \n",
      "26       1.002224      0.477400         0.002999    9.536743e-07      10   \n",
      "27       0.282841      0.010478         0.002600    4.896588e-04      10   \n",
      "28       0.126332      0.011783         0.002399    4.898435e-04      10   \n",
      "29       0.060410      0.002622         0.002955    6.408902e-04      10   \n",
      "\n",
      "   param_tol                       params  split0_test_score  \\\n",
      "0      1e-05   {'C': 1e-05, 'tol': 1e-05}             0.7995   \n",
      "1     0.0001  {'C': 1e-05, 'tol': 0.0001}             0.7995   \n",
      "2       0.01    {'C': 1e-05, 'tol': 0.01}             0.8005   \n",
      "3          1       {'C': 1e-05, 'tol': 1}             0.7975   \n",
      "4         10      {'C': 1e-05, 'tol': 10}             0.8050   \n",
      "5      1e-05   {'C': 0.001, 'tol': 1e-05}             0.8540   \n",
      "6     0.0001  {'C': 0.001, 'tol': 0.0001}             0.8540   \n",
      "7       0.01    {'C': 0.001, 'tol': 0.01}             0.8540   \n",
      "8          1       {'C': 0.001, 'tol': 1}             0.8535   \n",
      "9         10      {'C': 0.001, 'tol': 10}             0.8585   \n",
      "10     1e-05    {'C': 0.01, 'tol': 1e-05}             0.8705   \n",
      "11    0.0001   {'C': 0.01, 'tol': 0.0001}             0.8705   \n",
      "12      0.01     {'C': 0.01, 'tol': 0.01}             0.8705   \n",
      "13         1        {'C': 0.01, 'tol': 1}             0.8700   \n",
      "14        10       {'C': 0.01, 'tol': 10}             0.8220   \n",
      "15     1e-05       {'C': 1, 'tol': 1e-05}             0.8310   \n",
      "16    0.0001      {'C': 1, 'tol': 0.0001}             0.8310   \n",
      "17      0.01        {'C': 1, 'tol': 0.01}             0.8310   \n",
      "18         1           {'C': 1, 'tol': 1}             0.8365   \n",
      "19        10          {'C': 1, 'tol': 10}             0.8415   \n",
      "20     1e-05       {'C': 2, 'tol': 1e-05}             0.8305   \n",
      "21    0.0001      {'C': 2, 'tol': 0.0001}             0.8300   \n",
      "22      0.01        {'C': 2, 'tol': 0.01}             0.8295   \n",
      "23         1           {'C': 2, 'tol': 1}             0.8340   \n",
      "24        10          {'C': 2, 'tol': 10}             0.8395   \n",
      "25     1e-05      {'C': 10, 'tol': 1e-05}             0.8310   \n",
      "26    0.0001     {'C': 10, 'tol': 0.0001}             0.8310   \n",
      "27      0.01       {'C': 10, 'tol': 0.01}             0.8315   \n",
      "28         1          {'C': 10, 'tol': 1}             0.8325   \n",
      "29        10         {'C': 10, 'tol': 10}             0.8305   \n",
      "\n",
      "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
      "0              0.7825             0.7830       ...                  0.7847   \n",
      "1              0.7825             0.7830       ...                  0.7847   \n",
      "2              0.7830             0.7830       ...                  0.7850   \n",
      "3              0.7595             0.7665       ...                  0.7782   \n",
      "4              0.7715             0.7905       ...                  0.7794   \n",
      "5              0.8640             0.8595       ...                  0.8566   \n",
      "6              0.8640             0.8595       ...                  0.8566   \n",
      "7              0.8640             0.8595       ...                  0.8566   \n",
      "8              0.8635             0.8600       ...                  0.8565   \n",
      "9              0.8570             0.8575       ...                  0.8494   \n",
      "10             0.8660             0.8585       ...                  0.8637   \n",
      "11             0.8660             0.8585       ...                  0.8637   \n",
      "12             0.8660             0.8585       ...                  0.8637   \n",
      "13             0.8675             0.8580       ...                  0.8636   \n",
      "14             0.8300             0.8265       ...                  0.8325   \n",
      "15             0.8235             0.8265       ...                  0.8277   \n",
      "16             0.8240             0.8265       ...                  0.8278   \n",
      "17             0.8235             0.8265       ...                  0.8277   \n",
      "18             0.8295             0.8240       ...                  0.8301   \n",
      "19             0.8265             0.8350       ...                  0.8242   \n",
      "20             0.8245             0.8265       ...                  0.8279   \n",
      "21             0.8245             0.8270       ...                  0.8279   \n",
      "22             0.8245             0.8270       ...                  0.8278   \n",
      "23             0.8295             0.8245       ...                  0.8298   \n",
      "24             0.8425             0.8480       ...                  0.8330   \n",
      "25             0.8265             0.8255       ...                  0.8273   \n",
      "26             0.8260             0.8255       ...                  0.8272   \n",
      "27             0.8260             0.8255       ...                  0.8273   \n",
      "28             0.8260             0.8255       ...                  0.8284   \n",
      "29             0.8455             0.8385       ...                  0.8299   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.008262               27            0.794875            0.796250   \n",
      "1         0.008262               27            0.794875            0.796250   \n",
      "2         0.008597               26            0.794875            0.796500   \n",
      "3         0.014538               30            0.802000            0.780000   \n",
      "4         0.018001               29            0.804375            0.788750   \n",
      "5         0.004465                5            0.905250            0.903875   \n",
      "6         0.004465                5            0.905250            0.903875   \n",
      "7         0.004465                5            0.905250            0.903875   \n",
      "8         0.004438                8            0.905000            0.903750   \n",
      "9         0.010618                9            0.887625            0.890875   \n",
      "10        0.004155                1            0.972125            0.972250   \n",
      "11        0.004155                1            0.972125            0.972250   \n",
      "12        0.004155                1            0.972125            0.972250   \n",
      "13        0.004465                4            0.970250            0.972000   \n",
      "14        0.008643               11            0.871250            0.884875   \n",
      "15        0.003696               20            1.000000            1.000000   \n",
      "16        0.003586               18            1.000000            1.000000   \n",
      "17        0.003696               20            1.000000            1.000000   \n",
      "18        0.004212               12            1.000000            1.000000   \n",
      "19        0.018568               25            0.900250            0.888500   \n",
      "20        0.003308               16            1.000000            1.000000   \n",
      "21        0.003200               16            1.000000            1.000000   \n",
      "22        0.003140               18            1.000000            1.000000   \n",
      "23        0.003124               14            1.000000            1.000000   \n",
      "24        0.013405               10            0.897000            0.907625   \n",
      "25        0.002804               22            1.000000            1.000000   \n",
      "26        0.002839               24            1.000000            1.000000   \n",
      "27        0.002977               22            1.000000            1.000000   \n",
      "28        0.002596               15            1.000000            1.000000   \n",
      "29        0.012847               13            0.907250            0.908125   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0             0.800750            0.796000            0.802625   \n",
      "1             0.800750            0.796000            0.802625   \n",
      "2             0.800750            0.796000            0.802625   \n",
      "3             0.782500            0.804750            0.807375   \n",
      "4             0.803750            0.773000            0.808000   \n",
      "5             0.906250            0.906375            0.907000   \n",
      "6             0.906250            0.906375            0.907000   \n",
      "7             0.906250            0.906250            0.907000   \n",
      "8             0.906125            0.906000            0.907000   \n",
      "9             0.888875            0.879750            0.889750   \n",
      "10            0.972125            0.972250            0.974250   \n",
      "11            0.972125            0.972250            0.974250   \n",
      "12            0.972125            0.972250            0.974125   \n",
      "13            0.972125            0.971750            0.973500   \n",
      "14            0.898125            0.904500            0.913125   \n",
      "15            1.000000            1.000000            1.000000   \n",
      "16            1.000000            1.000000            1.000000   \n",
      "17            1.000000            1.000000            1.000000   \n",
      "18            1.000000            1.000000            1.000000   \n",
      "19            0.915875            0.852000            0.919375   \n",
      "20            1.000000            1.000000            1.000000   \n",
      "21            1.000000            1.000000            1.000000   \n",
      "22            1.000000            1.000000            1.000000   \n",
      "23            1.000000            1.000000            1.000000   \n",
      "24            0.917125            0.884875            0.879625   \n",
      "25            1.000000            1.000000            1.000000   \n",
      "26            1.000000            1.000000            1.000000   \n",
      "27            1.000000            1.000000            1.000000   \n",
      "28            1.000000            1.000000            1.000000   \n",
      "29            0.924375            0.881500            0.915250   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.798100         0.003024  \n",
      "1           0.798100         0.003024  \n",
      "2           0.798150         0.002995  \n",
      "3           0.795325         0.011644  \n",
      "4           0.795575         0.013076  \n",
      "5           0.905750         0.001093  \n",
      "6           0.905750         0.001093  \n",
      "7           0.905725         0.001079  \n",
      "8           0.905575         0.001111  \n",
      "9           0.887375         0.003958  \n",
      "10          0.972600         0.000827  \n",
      "11          0.972600         0.000827  \n",
      "12          0.972575         0.000777  \n",
      "13          0.971925         0.001036  \n",
      "14          0.894375         0.014786  \n",
      "15          1.000000         0.000000  \n",
      "16          1.000000         0.000000  \n",
      "17          1.000000         0.000000  \n",
      "18          1.000000         0.000000  \n",
      "19          0.895200         0.024284  \n",
      "20          1.000000         0.000000  \n",
      "21          1.000000         0.000000  \n",
      "22          1.000000         0.000000  \n",
      "23          1.000000         0.000000  \n",
      "24          0.897250         0.013903  \n",
      "25          1.000000         0.000000  \n",
      "26          1.000000         0.000000  \n",
      "27          1.000000         0.000000  \n",
      "28          1.000000         0.000000  \n",
      "29          0.907300         0.014290  \n",
      "\n",
      "[30 rows x 22 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'C': 0.01, 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "calculate_base(IMDB_BBOW['train'][0],IMDB_BBOW['train'][1])\n",
    "print('\\n')\n",
    "\n",
    "parametersBN = {'alpha': [0.0000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 30]}\n",
    "get_BernoulliNBParams(IMDB_BBOW['valid'][0], IMDB_BBOW['valid'][1],parametersBN)\n",
    "print('\\n')\n",
    "\n",
    "parametersDTC = {'max_depth': [10,12,14,16,20], 'min_samples_split': [2,4,6,8,10], \"max_features\": [1000, 2000, 3000, 4000]}\n",
    "get_DecisionTreesParams(IMDB_BBOW['valid'][0],IMDB_BBOW['valid'][1], parametersDTC)\n",
    "print('\\n')\n",
    "\n",
    "parametersSVC = {'tol': [0.00001, 0.0001, 0.01, 1, 10], 'C': [0.00001, 0.001, 0.01, 1, 2, 10]}\n",
    "get_SVCParams(IMDB_BBOW['valid'][0],IMDB_BBOW['valid'][1], parametersSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores for train set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 1\n",
      "86.94\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 16 4000 8\n",
      "82.69999999999999\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1\n",
      "96.24666666666667\n",
      "\n",
      "\n",
      "F1-scores for valid set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 1\n",
      "88.71\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 16 4000 8\n",
      "84.46000000000001\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1\n",
      "96.87\n",
      "\n",
      "\n",
      "F1-scores for test set\n",
      "\n",
      "F1-score for bernoulli for hyperparameter: 1\n",
      "87.08\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 16 4000 8\n",
      "80.728\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 0.01 1\n",
      "95.348\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1-scores for train set\\n')\n",
    "calculate_BernoulliNB(IMDB_BBOW['train'][0], IMDB_BBOW['train'][1], 1)\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(IMDB_BBOW['train'][0], IMDB_BBOW['train'][1], 16, 4000, 8)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_BBOW['train'][0], IMDB_BBOW['train'][1], 0.01, 1)\n",
    "print('\\n')\n",
    "print('F1-scores for valid set\\n')\n",
    "calculate_BernoulliNB(IMDB_BBOW['valid'][0], IMDB_BBOW['valid'][1], 1)\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(IMDB_BBOW['valid'][0], IMDB_BBOW['valid'][1], 16, 4000, 8)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_BBOW['valid'][0], IMDB_BBOW['valid'][1], 0.01, 1)\n",
    "print('\\n')\n",
    "print('F1-scores for test set\\n')\n",
    "calculate_BernoulliNB(IMDB_BBOW['test'][0], IMDB_BBOW['test'][1], 1 )\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(IMDB_BBOW['test'][0], IMDB_BBOW['test'][1], 16, 4000, 8)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_BBOW['test'][0], IMDB_BBOW['test'][1], 0.01, 1)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Decision Tree: \n",
      "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.121332      0.041835         0.015013        0.007473   \n",
      "1         0.110941      0.025621         0.010795        0.001832   \n",
      "2         0.087150      0.002306         0.008999        0.000007   \n",
      "3         0.081752      0.003485         0.009400        0.000487   \n",
      "4         0.084755      0.010159         0.009392        0.001349   \n",
      "5         0.082555      0.007831         0.009199        0.000978   \n",
      "6         0.078555      0.002331         0.008214        0.000399   \n",
      "7         0.134927      0.014549         0.008995        0.001092   \n",
      "8         0.125728      0.009615         0.008799        0.000743   \n",
      "9         0.106136      0.002317         0.008395        0.000490   \n",
      "10        0.107934      0.010694         0.008596        0.000800   \n",
      "11        0.110531      0.014221         0.009995        0.001788   \n",
      "12        0.101740      0.015109         0.009000        0.000627   \n",
      "13        0.100339      0.006789         0.009598        0.001021   \n",
      "14        0.165105      0.016008         0.008607        0.000491   \n",
      "15        0.140515      0.002417         0.008995        0.001095   \n",
      "16        0.125123      0.002135         0.008407        0.000497   \n",
      "17        0.128729      0.015101         0.009207        0.001161   \n",
      "18        0.114333      0.016356         0.008804        0.000750   \n",
      "19        0.105744      0.003548         0.008596        0.000482   \n",
      "20        0.105547      0.001858         0.008599        0.000492   \n",
      "21        0.202887      0.019927         0.009396        0.000800   \n",
      "22        0.190094      0.012659         0.009195        0.000401   \n",
      "23        0.158708      0.010641         0.009205        0.000402   \n",
      "24        0.147917      0.014992         0.009000        0.001091   \n",
      "25        0.127926      0.002606         0.008207        0.000403   \n",
      "26        0.134730      0.009976         0.008992        0.001096   \n",
      "27        0.136720      0.014474         0.009200        0.001166   \n",
      "28        0.275444      0.013193         0.009000        0.001546   \n",
      "29        0.323614      0.035948         0.010199        0.001466   \n",
      "..             ...           ...              ...             ...   \n",
      "362       0.142118      0.003918         0.010195        0.001166   \n",
      "363       0.135122      0.005033         0.009199        0.000752   \n",
      "364       0.305224      0.008908         0.009595        0.001355   \n",
      "365       0.287435      0.032549         0.009196        0.000979   \n",
      "366       0.247857      0.006779         0.009795        0.001327   \n",
      "367       0.244459      0.039096         0.009795        0.000748   \n",
      "368       0.237063      0.014735         0.008795        0.000748   \n",
      "369       0.205482      0.011476         0.009395        0.001020   \n",
      "370       0.203682      0.008813         0.008796        0.000400   \n",
      "371       0.608650      0.012594         0.009396        0.000489   \n",
      "372       0.546286      0.007168         0.009795        0.000748   \n",
      "373       0.530695      0.036721         0.010795        0.001832   \n",
      "374       0.544488      0.052639         0.009994        0.001092   \n",
      "375       0.505909      0.063604         0.009995        0.001413   \n",
      "376       0.644230      0.109469         0.013193        0.004746   \n",
      "377       0.396173      0.040958         0.008603        0.000793   \n",
      "378       0.801539      0.136021         0.016591        0.014227   \n",
      "379       0.596853      0.026947         0.008203        0.000404   \n",
      "380       0.571872      0.029583         0.008803        0.000404   \n",
      "381       0.532698      0.023228         0.008403        0.000491   \n",
      "382       0.474728      0.011910         0.008196        0.000401   \n",
      "383       0.466932      0.009783         0.008600        0.000493   \n",
      "384       0.461339      0.022713         0.008804        0.000395   \n",
      "385       0.769366      0.031664         0.008395        0.000491   \n",
      "386       0.716589      0.039581         0.008603        0.000489   \n",
      "387       0.684003      0.046124         0.008996        0.001095   \n",
      "388       0.659422      0.031317         0.008403        0.000498   \n",
      "389       0.577669      0.028233         0.008404        0.000484   \n",
      "390       0.560278      0.018192         0.008200        0.000398   \n",
      "391       0.555882      0.046221         0.013195        0.008394   \n",
      "\n",
      "    param_max_depth param_max_features param_min_samples_split  \\\n",
      "0                60                 20                      10   \n",
      "1                60                 20                      20   \n",
      "2                60                 20                      40   \n",
      "3                60                 20                      60   \n",
      "4                60                 20                      80   \n",
      "5                60                 20                      90   \n",
      "6                60                 20                     100   \n",
      "7                60                 40                      10   \n",
      "8                60                 40                      20   \n",
      "9                60                 40                      40   \n",
      "10               60                 40                      60   \n",
      "11               60                 40                      80   \n",
      "12               60                 40                      90   \n",
      "13               60                 40                     100   \n",
      "14               60                 60                      10   \n",
      "15               60                 60                      20   \n",
      "16               60                 60                      40   \n",
      "17               60                 60                      60   \n",
      "18               60                 60                      80   \n",
      "19               60                 60                      90   \n",
      "20               60                 60                     100   \n",
      "21               60                100                      10   \n",
      "22               60                100                      20   \n",
      "23               60                100                      40   \n",
      "24               60                100                      60   \n",
      "25               60                100                      80   \n",
      "26               60                100                      90   \n",
      "27               60                100                     100   \n",
      "28               60                200                      10   \n",
      "29               60                200                      20   \n",
      "..              ...                ...                     ...   \n",
      "362            1000                100                      90   \n",
      "363            1000                100                     100   \n",
      "364            1000                200                      10   \n",
      "365            1000                200                      20   \n",
      "366            1000                200                      40   \n",
      "367            1000                200                      60   \n",
      "368            1000                200                      80   \n",
      "369            1000                200                      90   \n",
      "370            1000                200                     100   \n",
      "371            1000                600                      10   \n",
      "372            1000                600                      20   \n",
      "373            1000                600                      40   \n",
      "374            1000                600                      60   \n",
      "375            1000                600                      80   \n",
      "376            1000                600                      90   \n",
      "377            1000                600                     100   \n",
      "378            1000                800                      10   \n",
      "379            1000                800                      20   \n",
      "380            1000                800                      40   \n",
      "381            1000                800                      60   \n",
      "382            1000                800                      80   \n",
      "383            1000                800                      90   \n",
      "384            1000                800                     100   \n",
      "385            1000               1000                      10   \n",
      "386            1000               1000                      20   \n",
      "387            1000               1000                      40   \n",
      "388            1000               1000                      60   \n",
      "389            1000               1000                      80   \n",
      "390            1000               1000                      90   \n",
      "391            1000               1000                     100   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6130   \n",
      "1    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6065   \n",
      "2    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.5995   \n",
      "3    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6005   \n",
      "4    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6235   \n",
      "5    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6490   \n",
      "6    {'max_depth': 60, 'max_features': 20, 'min_sam...             0.6555   \n",
      "7    {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6285   \n",
      "8    {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6325   \n",
      "9    {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6155   \n",
      "10   {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6330   \n",
      "11   {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6590   \n",
      "12   {'max_depth': 60, 'max_features': 40, 'min_sam...             0.5960   \n",
      "13   {'max_depth': 60, 'max_features': 40, 'min_sam...             0.6320   \n",
      "14   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6320   \n",
      "15   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6265   \n",
      "16   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6325   \n",
      "17   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6320   \n",
      "18   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6345   \n",
      "19   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6395   \n",
      "20   {'max_depth': 60, 'max_features': 60, 'min_sam...             0.6415   \n",
      "21   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6430   \n",
      "22   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6540   \n",
      "23   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6430   \n",
      "24   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6360   \n",
      "25   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6485   \n",
      "26   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6265   \n",
      "27   {'max_depth': 60, 'max_features': 100, 'min_sa...             0.6350   \n",
      "28   {'max_depth': 60, 'max_features': 200, 'min_sa...             0.6335   \n",
      "29   {'max_depth': 60, 'max_features': 200, 'min_sa...             0.6255   \n",
      "..                                                 ...                ...   \n",
      "362  {'max_depth': 1000, 'max_features': 100, 'min_...             0.6410   \n",
      "363  {'max_depth': 1000, 'max_features': 100, 'min_...             0.6260   \n",
      "364  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6475   \n",
      "365  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6530   \n",
      "366  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6455   \n",
      "367  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6655   \n",
      "368  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6495   \n",
      "369  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6615   \n",
      "370  {'max_depth': 1000, 'max_features': 200, 'min_...             0.6380   \n",
      "371  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6600   \n",
      "372  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6480   \n",
      "373  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6540   \n",
      "374  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6680   \n",
      "375  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6830   \n",
      "376  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6910   \n",
      "377  {'max_depth': 1000, 'max_features': 600, 'min_...             0.6740   \n",
      "378  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6695   \n",
      "379  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6660   \n",
      "380  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6815   \n",
      "381  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6760   \n",
      "382  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6850   \n",
      "383  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6610   \n",
      "384  {'max_depth': 1000, 'max_features': 800, 'min_...             0.6855   \n",
      "385  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6765   \n",
      "386  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6685   \n",
      "387  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6890   \n",
      "388  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6600   \n",
      "389  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6835   \n",
      "390  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6880   \n",
      "391  {'max_depth': 1000, 'max_features': 1000, 'min...             0.6765   \n",
      "\n",
      "     split1_test_score       ...         mean_test_score  std_test_score  \\\n",
      "0               0.6090       ...                  0.6107        0.005183   \n",
      "1               0.6310       ...                  0.6159        0.014620   \n",
      "2               0.6170       ...                  0.6061        0.011106   \n",
      "3               0.6130       ...                  0.6121        0.020527   \n",
      "4               0.6235       ...                  0.6229        0.004176   \n",
      "5               0.6355       ...                  0.6236        0.016259   \n",
      "6               0.6245       ...                  0.6152        0.024174   \n",
      "7               0.6250       ...                  0.6161        0.011469   \n",
      "8               0.6345       ...                  0.6268        0.007373   \n",
      "9               0.6060       ...                  0.6212        0.012604   \n",
      "10              0.6355       ...                  0.6239        0.010665   \n",
      "11              0.6385       ...                  0.6388        0.010975   \n",
      "12              0.6415       ...                  0.6142        0.017259   \n",
      "13              0.6470       ...                  0.6277        0.012921   \n",
      "14              0.6390       ...                  0.6240        0.012806   \n",
      "15              0.6220       ...                  0.6252        0.015292   \n",
      "16              0.6275       ...                  0.6254        0.012126   \n",
      "17              0.6485       ...                  0.6333        0.015481   \n",
      "18              0.6490       ...                  0.6305        0.022561   \n",
      "19              0.6215       ...                  0.6247        0.012624   \n",
      "20              0.6405       ...                  0.6274        0.011964   \n",
      "21              0.6265       ...                  0.6351        0.012043   \n",
      "22              0.6515       ...                  0.6472        0.010240   \n",
      "23              0.6135       ...                  0.6302        0.009595   \n",
      "24              0.6415       ...                  0.6398        0.004567   \n",
      "25              0.6220       ...                  0.6308        0.015148   \n",
      "26              0.6575       ...                  0.6387        0.013801   \n",
      "27              0.6470       ...                  0.6489        0.008663   \n",
      "28              0.6270       ...                  0.6350        0.009884   \n",
      "29              0.6375       ...                  0.6418        0.018181   \n",
      "..                 ...       ...                     ...             ...   \n",
      "362             0.6385       ...                  0.6298        0.010299   \n",
      "363             0.6425       ...                  0.6242        0.016786   \n",
      "364             0.6185       ...                  0.6368        0.013956   \n",
      "365             0.6475       ...                  0.6458        0.012508   \n",
      "366             0.6505       ...                  0.6498        0.016281   \n",
      "367             0.6530       ...                  0.6536        0.006216   \n",
      "368             0.6630       ...                  0.6565        0.006156   \n",
      "369             0.6910       ...                  0.6662        0.016070   \n",
      "370             0.6655       ...                  0.6559        0.010022   \n",
      "371             0.6635       ...                  0.6580        0.015418   \n",
      "372             0.6675       ...                  0.6530        0.014816   \n",
      "373             0.6635       ...                  0.6620        0.013042   \n",
      "374             0.6665       ...                  0.6662        0.005026   \n",
      "375             0.6745       ...                  0.6731        0.006045   \n",
      "376             0.6760       ...                  0.6835        0.006229   \n",
      "377             0.6910       ...                  0.6728        0.015756   \n",
      "378             0.6780       ...                  0.6769        0.006492   \n",
      "379             0.6700       ...                  0.6642        0.006845   \n",
      "380             0.6750       ...                  0.6764        0.008517   \n",
      "381             0.6875       ...                  0.6759        0.010195   \n",
      "382             0.6770       ...                  0.6708        0.009636   \n",
      "383             0.6760       ...                  0.6752        0.011268   \n",
      "384             0.6870       ...                  0.6757        0.014417   \n",
      "385             0.6610       ...                  0.6655        0.005797   \n",
      "386             0.6855       ...                  0.6720        0.010498   \n",
      "387             0.6910       ...                  0.6791        0.011209   \n",
      "388             0.6820       ...                  0.6696        0.011539   \n",
      "389             0.7015       ...                  0.6778        0.015861   \n",
      "390             0.6770       ...                  0.6792        0.011843   \n",
      "391             0.6895       ...                  0.6821        0.006719   \n",
      "\n",
      "     rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0                362            0.871250            0.828375   \n",
      "1                339            0.797250            0.842500   \n",
      "2                383            0.785750            0.797375   \n",
      "3                358            0.745875            0.790375   \n",
      "4                306            0.775375            0.768375   \n",
      "5                301            0.780625            0.742250   \n",
      "6                343            0.742625            0.783125   \n",
      "7                337            0.886875            0.896750   \n",
      "8                278            0.871250            0.881500   \n",
      "9                320            0.855125            0.847000   \n",
      "10               299            0.830125            0.819500   \n",
      "11               205            0.822375            0.808875   \n",
      "12               347            0.784625            0.794125   \n",
      "13               273            0.789125            0.794625   \n",
      "14               298            0.926000            0.930625   \n",
      "15               289            0.895000            0.888750   \n",
      "16               287            0.855750            0.850375   \n",
      "17               238            0.830375            0.832500   \n",
      "18               254            0.829125            0.826500   \n",
      "19               291            0.819625            0.814875   \n",
      "20               275            0.813625            0.810875   \n",
      "21               224            0.926250            0.948250   \n",
      "22               177            0.922250            0.903375   \n",
      "23               257            0.861875            0.864125   \n",
      "24               204            0.855625            0.838500   \n",
      "25               252            0.831250            0.818250   \n",
      "26               207            0.831625            0.815125   \n",
      "27               173            0.812500            0.803000   \n",
      "28               227            0.953000            0.954125   \n",
      "29               194            0.924875            0.923875   \n",
      "..               ...                 ...                 ...   \n",
      "362              261            0.834875            0.824375   \n",
      "363              295            0.826000            0.819875   \n",
      "364              217            0.961875            0.954750   \n",
      "365              182            0.929000            0.920875   \n",
      "366              170            0.888500            0.892375   \n",
      "367              159            0.874625            0.863375   \n",
      "368              151            0.852375            0.840875   \n",
      "369              127            0.852000            0.851250   \n",
      "370              152            0.841750            0.826125   \n",
      "371              146            0.964500            0.964750   \n",
      "372              161            0.937875            0.936250   \n",
      "373              142            0.912125            0.918125   \n",
      "374              127            0.900750            0.881875   \n",
      "375               84            0.873250            0.875625   \n",
      "376                9            0.893375            0.865625   \n",
      "377               88            0.879000            0.863125   \n",
      "378               47            0.964250            0.967375   \n",
      "379              137            0.942500            0.937250   \n",
      "380               53            0.909250            0.917625   \n",
      "381               57            0.897250            0.896375   \n",
      "382              103            0.881875            0.859750   \n",
      "383               66            0.869750            0.874875   \n",
      "384               60            0.877375            0.860625   \n",
      "385              131            0.969000            0.968250   \n",
      "386               92            0.942500            0.933750   \n",
      "387               30            0.917000            0.925375   \n",
      "388              112            0.900125            0.901125   \n",
      "389               42            0.885625            0.878500   \n",
      "390               28            0.887125            0.882000   \n",
      "391               15            0.862375            0.858500   \n",
      "\n",
      "     split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0              0.839375            0.859750            0.859750   \n",
      "1              0.820250            0.812875            0.813125   \n",
      "2              0.777000            0.779250            0.800875   \n",
      "3              0.769125            0.802125            0.778000   \n",
      "4              0.786500            0.767250            0.763875   \n",
      "5              0.768125            0.768500            0.737750   \n",
      "6              0.759375            0.732625            0.761250   \n",
      "7              0.891750            0.913875            0.919500   \n",
      "8              0.862250            0.890375            0.878375   \n",
      "9              0.837750            0.847250            0.836375   \n",
      "10             0.803250            0.818375            0.832250   \n",
      "11             0.797000            0.804750            0.810625   \n",
      "12             0.804500            0.784500            0.801625   \n",
      "13             0.789625            0.797625            0.806750   \n",
      "14             0.927750            0.938250            0.934750   \n",
      "15             0.890250            0.897875            0.897375   \n",
      "16             0.863875            0.847250            0.868000   \n",
      "17             0.830750            0.829125            0.842875   \n",
      "18             0.803250            0.804000            0.815000   \n",
      "19             0.801375            0.818500            0.799375   \n",
      "20             0.803750            0.792375            0.796375   \n",
      "21             0.937500            0.932125            0.943250   \n",
      "22             0.912875            0.908500            0.908625   \n",
      "23             0.875000            0.878000            0.869000   \n",
      "24             0.846750            0.853000            0.862250   \n",
      "25             0.832750            0.825000            0.821250   \n",
      "26             0.838750            0.818000            0.822500   \n",
      "27             0.823125            0.830250            0.817875   \n",
      "28             0.949250            0.958625            0.959500   \n",
      "29             0.921250            0.929250            0.920500   \n",
      "..                  ...                 ...                 ...   \n",
      "362            0.826625            0.823625            0.825250   \n",
      "363            0.800375            0.804875            0.816125   \n",
      "364            0.957250            0.956625            0.957625   \n",
      "365            0.925625            0.927125            0.929375   \n",
      "366            0.900625            0.888750            0.892000   \n",
      "367            0.866000            0.868250            0.864875   \n",
      "368            0.867250            0.856500            0.868000   \n",
      "369            0.834375            0.844000            0.839750   \n",
      "370            0.843875            0.852625            0.850375   \n",
      "371            0.967250            0.965375            0.962125   \n",
      "372            0.931625            0.940250            0.944125   \n",
      "373            0.907375            0.914000            0.891125   \n",
      "374            0.886625            0.892625            0.895125   \n",
      "375            0.866375            0.878875            0.864125   \n",
      "376            0.874125            0.894500            0.861750   \n",
      "377            0.851125            0.871125            0.842875   \n",
      "378            0.965250            0.966375            0.963750   \n",
      "379            0.936125            0.942750            0.941875   \n",
      "380            0.896625            0.914750            0.915375   \n",
      "381            0.889000            0.891000            0.901750   \n",
      "382            0.879375            0.879500            0.866625   \n",
      "383            0.876375            0.866000            0.862000   \n",
      "384            0.870625            0.851375            0.857750   \n",
      "385            0.966375            0.974000            0.967250   \n",
      "386            0.943250            0.944375            0.942875   \n",
      "387            0.913875            0.913875            0.920750   \n",
      "388            0.898750            0.886000            0.889250   \n",
      "389            0.870250            0.884625            0.892500   \n",
      "390            0.879000            0.879875            0.875250   \n",
      "391            0.869500            0.869750            0.860750   \n",
      "\n",
      "     mean_train_score  std_train_score  \n",
      "0            0.851700         0.015542  \n",
      "1            0.817200         0.014715  \n",
      "2            0.788050         0.009553  \n",
      "3            0.777100         0.019193  \n",
      "4            0.772275         0.008037  \n",
      "5            0.759450         0.016567  \n",
      "6            0.755800         0.017319  \n",
      "7            0.901750         0.012715  \n",
      "8            0.876750         0.009501  \n",
      "9            0.844700         0.006900  \n",
      "10           0.820700         0.010330  \n",
      "11           0.808725         0.008285  \n",
      "12           0.793875         0.008324  \n",
      "13           0.795550         0.006434  \n",
      "14           0.931475         0.004499  \n",
      "15           0.893850         0.003713  \n",
      "16           0.857050         0.007858  \n",
      "17           0.833125         0.004993  \n",
      "18           0.815575         0.010855  \n",
      "19           0.810750         0.008639  \n",
      "20           0.803400         0.008142  \n",
      "21           0.937475         0.007798  \n",
      "22           0.911125         0.006325  \n",
      "23           0.869600         0.006160  \n",
      "24           0.851225         0.008075  \n",
      "25           0.825700         0.005591  \n",
      "26           0.825200         0.008781  \n",
      "27           0.817350         0.009268  \n",
      "28           0.954900         0.003773  \n",
      "29           0.923950         0.003103  \n",
      "..                ...              ...  \n",
      "362          0.826950         0.004086  \n",
      "363          0.813450         0.009491  \n",
      "364          0.957625         0.002344  \n",
      "365          0.926400         0.003074  \n",
      "366          0.892450         0.004389  \n",
      "367          0.867425         0.003936  \n",
      "368          0.857000         0.010077  \n",
      "369          0.844275         0.006736  \n",
      "370          0.842950         0.009318  \n",
      "371          0.964800         0.001648  \n",
      "372          0.938025         0.004154  \n",
      "373          0.908550         0.009372  \n",
      "374          0.891400         0.006578  \n",
      "375          0.871650         0.005568  \n",
      "376          0.877875         0.013717  \n",
      "377          0.861450         0.013085  \n",
      "378          0.965400         0.001336  \n",
      "379          0.940100         0.002823  \n",
      "380          0.910725         0.007569  \n",
      "381          0.895075         0.004571  \n",
      "382          0.873425         0.008683  \n",
      "383          0.869800         0.005372  \n",
      "384          0.863550         0.009291  \n",
      "385          0.968975         0.002665  \n",
      "386          0.941350         0.003851  \n",
      "387          0.918175         0.004401  \n",
      "388          0.895050         0.006195  \n",
      "389          0.882300         0.007485  \n",
      "390          0.880650         0.003905  \n",
      "391          0.864175         0.004618  \n",
      "\n",
      "[392 rows x 23 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'max_depth': 200, 'max_features': 800, 'min_samples_split': 90}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance of hyperparameters in Linear SVC: \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0        0.047377      0.003822         0.001800    4.003796e-04   1e-06   \n",
      "1        0.038183      0.001162         0.001999    2.429531e-06   1e-06   \n",
      "2        0.032196      0.004117         0.001397    4.898255e-04   1e-06   \n",
      "3        0.029592      0.001349         0.001402    4.853744e-04   1e-06   \n",
      "4        0.029990      0.001409         0.001396    4.846703e-04   1e-06   \n",
      "5        0.030591      0.001851         0.001994    7.583660e-06   1e-06   \n",
      "6        0.072560      0.003718         0.002603    1.197665e-03  0.0001   \n",
      "7        0.058968      0.001671         0.002398    4.899014e-04  0.0001   \n",
      "8        0.052775      0.000979         0.001199    4.000682e-04  0.0001   \n",
      "9        0.030989      0.002611         0.001601    4.877621e-04  0.0001   \n",
      "10       0.030380      0.002578         0.001999    5.560829e-07  0.0001   \n",
      "11       0.027785      0.000400         0.001799    3.996373e-04  0.0001   \n",
      "12       0.086360      0.003263         0.001796    3.974229e-04    0.01   \n",
      "13       0.070164      0.002035         0.001600    4.887529e-04    0.01   \n",
      "14       0.063776      0.002135         0.001792    3.960142e-04    0.01   \n",
      "15       0.045376      0.003553         0.001600    4.885004e-04    0.01   \n",
      "16       0.045187      0.002643         0.001801    4.001649e-04    0.01   \n",
      "17       0.029587      0.000796         0.001596    4.859421e-04    0.01   \n",
      "18       0.110742      0.004351         0.002198    3.985733e-04     0.1   \n",
      "19       0.083957      0.001673         0.001602    4.931562e-04     0.1   \n",
      "20       0.077761      0.004306         0.001800    3.989937e-04     0.1   \n",
      "21       0.053782      0.000746         0.001996    6.221583e-06     0.1   \n",
      "22       0.053977      0.001264         0.001801    4.000506e-04     0.1   \n",
      "23       0.030587      0.001203         0.001798    3.988058e-04     0.1   \n",
      "24       0.277043      0.011501         0.001396    4.847404e-04       1   \n",
      "25       0.203301      0.005311         0.001400    4.870143e-04       1   \n",
      "26       0.168505      0.004580         0.001599    4.890452e-04       1   \n",
      "27       0.103550      0.002499         0.001595    4.856063e-04       1   \n",
      "28       0.103945      0.002609         0.001995    8.087136e-06       1   \n",
      "29       0.028189      0.000751         0.001802    4.003079e-04       1   \n",
      "30       0.441357      0.016045         0.001800    3.999830e-04       2   \n",
      "31       0.307635      0.006965         0.001799    3.992929e-04       2   \n",
      "32       0.265052      0.005226         0.001600    4.884236e-04       2   \n",
      "33       0.144719      0.005112         0.001802    4.006301e-04       2   \n",
      "34       0.141119      0.003310         0.001602    4.919104e-04       2   \n",
      "35       0.028193      0.000750         0.001597    4.857886e-04       2   \n",
      "36       1.577898      0.334275         0.001201    3.995971e-04      10   \n",
      "37       1.012024      0.086609         0.001798    4.008776e-04      10   \n",
      "38       0.737390      0.015259         0.001794    3.998657e-04      10   \n",
      "39       0.365203      0.005270         0.001791    3.953350e-04      10   \n",
      "40       0.374792      0.022910         0.001799    3.998757e-04      10   \n",
      "41       0.027389      0.000487         0.001798    3.985475e-04      10   \n",
      "\n",
      "   param_tol                        params  split0_test_score  \\\n",
      "0      1e-06    {'C': 1e-06, 'tol': 1e-06}             0.6830   \n",
      "1     0.0001   {'C': 1e-06, 'tol': 0.0001}             0.6830   \n",
      "2      0.001    {'C': 1e-06, 'tol': 0.001}             0.6810   \n",
      "3        0.1      {'C': 1e-06, 'tol': 0.1}             0.6795   \n",
      "4        0.1      {'C': 1e-06, 'tol': 0.1}             0.6855   \n",
      "5         10       {'C': 1e-06, 'tol': 10}             0.6800   \n",
      "6      1e-06   {'C': 0.0001, 'tol': 1e-06}             0.6800   \n",
      "7     0.0001  {'C': 0.0001, 'tol': 0.0001}             0.6800   \n",
      "8      0.001   {'C': 0.0001, 'tol': 0.001}             0.6805   \n",
      "9        0.1     {'C': 0.0001, 'tol': 0.1}             0.5020   \n",
      "10       0.1     {'C': 0.0001, 'tol': 0.1}             0.6345   \n",
      "11        10      {'C': 0.0001, 'tol': 10}             0.5810   \n",
      "12     1e-06     {'C': 0.01, 'tol': 1e-06}             0.7540   \n",
      "13    0.0001    {'C': 0.01, 'tol': 0.0001}             0.7540   \n",
      "14     0.001     {'C': 0.01, 'tol': 0.001}             0.7540   \n",
      "15       0.1       {'C': 0.01, 'tol': 0.1}             0.7550   \n",
      "16       0.1       {'C': 0.01, 'tol': 0.1}             0.7545   \n",
      "17        10        {'C': 0.01, 'tol': 10}             0.7290   \n",
      "18     1e-06      {'C': 0.1, 'tol': 1e-06}             0.8400   \n",
      "19    0.0001     {'C': 0.1, 'tol': 0.0001}             0.8400   \n",
      "20     0.001      {'C': 0.1, 'tol': 0.001}             0.8400   \n",
      "21       0.1        {'C': 0.1, 'tol': 0.1}             0.8400   \n",
      "22       0.1        {'C': 0.1, 'tol': 0.1}             0.8395   \n",
      "23        10         {'C': 0.1, 'tol': 10}             0.8100   \n",
      "24     1e-06        {'C': 1, 'tol': 1e-06}             0.8730   \n",
      "25    0.0001       {'C': 1, 'tol': 0.0001}             0.8730   \n",
      "26     0.001        {'C': 1, 'tol': 0.001}             0.8730   \n",
      "27       0.1          {'C': 1, 'tol': 0.1}             0.8735   \n",
      "28       0.1          {'C': 1, 'tol': 0.1}             0.8740   \n",
      "29        10           {'C': 1, 'tol': 10}             0.8290   \n",
      "30     1e-06        {'C': 2, 'tol': 1e-06}             0.8770   \n",
      "31    0.0001       {'C': 2, 'tol': 0.0001}             0.8770   \n",
      "32     0.001        {'C': 2, 'tol': 0.001}             0.8770   \n",
      "33       0.1          {'C': 2, 'tol': 0.1}             0.8760   \n",
      "34       0.1          {'C': 2, 'tol': 0.1}             0.8755   \n",
      "35        10           {'C': 2, 'tol': 10}             0.7540   \n",
      "36     1e-06       {'C': 10, 'tol': 1e-06}             0.8630   \n",
      "37    0.0001      {'C': 10, 'tol': 0.0001}             0.8630   \n",
      "38     0.001       {'C': 10, 'tol': 0.001}             0.8630   \n",
      "39       0.1         {'C': 10, 'tol': 0.1}             0.8625   \n",
      "40       0.1         {'C': 10, 'tol': 0.1}             0.8630   \n",
      "41        10          {'C': 10, 'tol': 10}             0.8300   \n",
      "\n",
      "    split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
      "0              0.6735             0.6670       ...                  0.6664   \n",
      "1              0.6735             0.6670       ...                  0.6664   \n",
      "2              0.6720             0.6660       ...                  0.6647   \n",
      "3              0.6725             0.6685       ...                  0.6651   \n",
      "4              0.6705             0.6690       ...                  0.6645   \n",
      "5              0.6730             0.6685       ...                  0.6633   \n",
      "6              0.6725             0.6675       ...                  0.6681   \n",
      "7              0.6725             0.6675       ...                  0.6681   \n",
      "8              0.6725             0.6680       ...                  0.6685   \n",
      "9              0.5400             0.5175       ...                  0.5615   \n",
      "10             0.6000             0.5485       ...                  0.6071   \n",
      "11             0.6625             0.5155       ...                  0.5820   \n",
      "12             0.7510             0.7385       ...                  0.7420   \n",
      "13             0.7510             0.7385       ...                  0.7420   \n",
      "14             0.7510             0.7385       ...                  0.7420   \n",
      "15             0.7505             0.7380       ...                  0.7420   \n",
      "16             0.7525             0.7380       ...                  0.7424   \n",
      "17             0.7060             0.7215       ...                  0.7105   \n",
      "18             0.8330             0.8315       ...                  0.8287   \n",
      "19             0.8330             0.8315       ...                  0.8287   \n",
      "20             0.8330             0.8315       ...                  0.8287   \n",
      "21             0.8330             0.8315       ...                  0.8288   \n",
      "22             0.8330             0.8315       ...                  0.8285   \n",
      "23             0.8040             0.7945       ...                  0.7966   \n",
      "24             0.8730             0.8675       ...                  0.8670   \n",
      "25             0.8730             0.8675       ...                  0.8670   \n",
      "26             0.8730             0.8675       ...                  0.8670   \n",
      "27             0.8725             0.8670       ...                  0.8668   \n",
      "28             0.8735             0.8700       ...                  0.8678   \n",
      "29             0.8065             0.6875       ...                  0.7667   \n",
      "30             0.8795             0.8695       ...                  0.8710   \n",
      "31             0.8795             0.8695       ...                  0.8710   \n",
      "32             0.8795             0.8695       ...                  0.8710   \n",
      "33             0.8785             0.8700       ...                  0.8710   \n",
      "34             0.8780             0.8695       ...                  0.8700   \n",
      "35             0.8245             0.8145       ...                  0.7981   \n",
      "36             0.8660             0.8585       ...                  0.8604   \n",
      "37             0.8660             0.8585       ...                  0.8604   \n",
      "38             0.8660             0.8585       ...                  0.8604   \n",
      "39             0.8660             0.8575       ...                  0.8601   \n",
      "40             0.8660             0.8580       ...                  0.8602   \n",
      "41             0.7435             0.7815       ...                  0.7823   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.011399               34            0.672125            0.671875   \n",
      "1         0.011399               34            0.672125            0.671875   \n",
      "2         0.011285               37            0.671875            0.673000   \n",
      "3         0.010988               36            0.672500            0.671125   \n",
      "4         0.014481               38            0.671750            0.673500   \n",
      "5         0.014027               39            0.672375            0.673000   \n",
      "6         0.007586               32            0.674750            0.674375   \n",
      "7         0.007586               32            0.674750            0.674375   \n",
      "8         0.007570               31            0.674500            0.674500   \n",
      "9         0.055878               42            0.503500            0.538000   \n",
      "10        0.031698               40            0.641750            0.598250   \n",
      "11        0.064697               41            0.577750            0.666375   \n",
      "12        0.009006               26            0.752375            0.752375   \n",
      "13        0.009006               26            0.752375            0.752375   \n",
      "14        0.009006               26            0.752375            0.752375   \n",
      "15        0.009225               26            0.752625            0.752375   \n",
      "16        0.009367               25            0.753000            0.753375   \n",
      "17        0.016994               30            0.730250            0.711875   \n",
      "18        0.008340               17            0.856875            0.852250   \n",
      "19        0.008340               17            0.856875            0.852250   \n",
      "20        0.008340               17            0.856875            0.852125   \n",
      "21        0.008189               16            0.856750            0.852125   \n",
      "22        0.008361               20            0.856750            0.851875   \n",
      "23        0.013489               22            0.822500            0.817750   \n",
      "24        0.005505                7            0.935625            0.933625   \n",
      "25        0.005505                7            0.935625            0.933625   \n",
      "26        0.005505                7            0.935625            0.933625   \n",
      "27        0.005636               10            0.935000            0.933875   \n",
      "28        0.005938                6            0.935000            0.933250   \n",
      "29        0.051335               24            0.851125            0.826375   \n",
      "30        0.006372                1            0.955875            0.955125   \n",
      "31        0.006372                1            0.955875            0.955125   \n",
      "32        0.006372                1            0.955875            0.955000   \n",
      "33        0.005559                1            0.955750            0.954750   \n",
      "34        0.006189                5            0.955625            0.955000   \n",
      "35        0.024506               21            0.766375            0.849875   \n",
      "36        0.003787               11            0.993000            0.994000   \n",
      "37        0.003787               11            0.993000            0.994000   \n",
      "38        0.003787               11            0.993000            0.994000   \n",
      "39        0.003734               15            0.993000            0.993750   \n",
      "40        0.003868               14            0.993000            0.993750   \n",
      "41        0.028521               23            0.855125            0.742000   \n",
      "\n",
      "    split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0             0.675875            0.674750            0.662625   \n",
      "1             0.675875            0.674750            0.662625   \n",
      "2             0.676000            0.670625            0.662625   \n",
      "3             0.672750            0.670250            0.662125   \n",
      "4             0.672250            0.671500            0.659875   \n",
      "5             0.674875            0.670625            0.659250   \n",
      "6             0.678000            0.677250            0.672375   \n",
      "7             0.678000            0.677250            0.672375   \n",
      "8             0.677625            0.677625            0.672750   \n",
      "9             0.514375            0.607125            0.668875   \n",
      "10            0.548500            0.637125            0.644500   \n",
      "11            0.512875            0.503375            0.661250   \n",
      "12            0.754125            0.748250            0.752875   \n",
      "13            0.754125            0.748250            0.752875   \n",
      "14            0.754125            0.748250            0.752875   \n",
      "15            0.754250            0.748250            0.753125   \n",
      "16            0.754000            0.748250            0.753250   \n",
      "17            0.722875            0.731250            0.695625   \n",
      "18            0.855500            0.856125            0.858750   \n",
      "19            0.855500            0.856125            0.858750   \n",
      "20            0.855500            0.856125            0.858750   \n",
      "21            0.855500            0.856000            0.858875   \n",
      "22            0.854875            0.856375            0.858375   \n",
      "23            0.808625            0.834375            0.799750   \n",
      "24            0.935500            0.938125            0.935000   \n",
      "25            0.935500            0.938125            0.935000   \n",
      "26            0.935500            0.938125            0.935000   \n",
      "27            0.935625            0.937250            0.935125   \n",
      "28            0.935375            0.937875            0.934750   \n",
      "29            0.686875            0.759875            0.809500   \n",
      "30            0.956750            0.957000            0.958625   \n",
      "31            0.956750            0.957000            0.958625   \n",
      "32            0.956750            0.957000            0.958750   \n",
      "33            0.957000            0.957375            0.958500   \n",
      "34            0.957000            0.957125            0.957625   \n",
      "35            0.844875            0.842625            0.823125   \n",
      "36            0.994125            0.993625            0.994125   \n",
      "37            0.994125            0.993625            0.994125   \n",
      "38            0.994125            0.993625            0.994125   \n",
      "39            0.994000            0.993625            0.993875   \n",
      "40            0.994000            0.993625            0.994000   \n",
      "41            0.812125            0.805125            0.843000   \n",
      "\n",
      "    mean_train_score  std_train_score  \n",
      "0           0.671450         0.004669  \n",
      "1           0.671450         0.004669  \n",
      "2           0.670825         0.004470  \n",
      "3           0.669750         0.003920  \n",
      "4           0.669775         0.004998  \n",
      "5           0.670025         0.005556  \n",
      "6           0.675350         0.002039  \n",
      "7           0.675350         0.002039  \n",
      "8           0.675400         0.001926  \n",
      "9           0.566375         0.062657  \n",
      "10          0.614025         0.036806  \n",
      "11          0.584325         0.069787  \n",
      "12          0.752000         0.001981  \n",
      "13          0.752000         0.001981  \n",
      "14          0.752000         0.001981  \n",
      "15          0.752125         0.002042  \n",
      "16          0.752375         0.002089  \n",
      "17          0.718375         0.013318  \n",
      "18          0.855900         0.002126  \n",
      "19          0.855900         0.002126  \n",
      "20          0.855875         0.002169  \n",
      "21          0.855850         0.002190  \n",
      "22          0.855650         0.002191  \n",
      "23          0.816600         0.011829  \n",
      "24          0.935575         0.001459  \n",
      "25          0.935575         0.001459  \n",
      "26          0.935575         0.001459  \n",
      "27          0.935375         0.001098  \n",
      "28          0.935250         0.001498  \n",
      "29          0.786750         0.058188  \n",
      "30          0.956675         0.001180  \n",
      "31          0.956675         0.001180  \n",
      "32          0.956675         0.001254  \n",
      "33          0.956675         0.001303  \n",
      "34          0.956475         0.000992  \n",
      "35          0.825375         0.030868  \n",
      "36          0.993775         0.000429  \n",
      "37          0.993775         0.000429  \n",
      "38          0.993775         0.000429  \n",
      "39          0.993650         0.000348  \n",
      "40          0.993675         0.000367  \n",
      "41          0.811475         0.039412  \n",
      "\n",
      "[42 rows x 22 columns]\n",
      "\n",
      "\n",
      "Best hyperparameter:\n",
      "{'C': 2, 'tol': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "parametersDTC = {'max_depth': [60, 80, 100, 200, 400, 600, 1000], 'min_samples_split': [10, 20, 40, 60, 80, 90, 100], \"max_features\": [20, 40, 60, 100, 200, 600, 800, 1000]}\n",
    "get_DecisionTreesParams(IMDB_FBOW['valid'][0],IMDB_FBOW['valid'][1], parametersDTC)\n",
    "print('\\n')\n",
    "\n",
    "parametersSVC = {'tol': [0.000001, 0.0001, 0.001, 0.1, 0.1 , 10], 'C': [0.000001, 0.0001, 0.01, 0.1, 1, 2, 10]}\n",
    "get_SVCParams(IMDB_FBOW['valid'][0],IMDB_FBOW['valid'][1], parametersSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-scores for train set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "86.30666666666667\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 200 800 90\n",
      "62.87142857142857\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 2 1e-06\n",
      "95.10666666666665\n",
      "\n",
      "\n",
      "F1-scores for valid set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "87.39\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 200 800 90\n",
      "86.61\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 2 1e-06\n",
      "95.36\n",
      "\n",
      "\n",
      "F1-scores for test set\n",
      "\n",
      "F1-score for Gaussian:\n",
      "84.776\n",
      "\n",
      "\n",
      "F1-score for Decision Trees for hyperparameter: 200 800 90\n",
      "88.02799999999999\n",
      "\n",
      "\n",
      "F1-score for Linear SVC for hyperparameter: 2 1e-06\n",
      "94.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('F1-scores for train set\\n')\n",
    "calculate_GaussianNB((IMDB_FBOW['train'][0]).toarray(), IMDB_BBOW['train'][1])\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(Yelp_FBOW['train'][0], Yelp_FBOW['train'][1], 200, 800, 90)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_FBOW['train'][0], IMDB_FBOW['train'][1], 2, 1e-06)\n",
    "print('\\n')\n",
    "print('F1-scores for valid set\\n')\n",
    "calculate_GaussianNB((IMDB_FBOW['valid'][0]).toarray(), IMDB_FBOW['valid'][1])\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(IMDB_FBOW['valid'][0], IMDB_FBOW['valid'][1], 200, 800, 90)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_FBOW['valid'][0], IMDB_FBOW['valid'][1], 2, 1e-06)\n",
    "print('\\n')\n",
    "print('F1-scores for test set\\n')\n",
    "calculate_GaussianNB((IMDB_FBOW['test'][0]).toarray(), IMDB_FBOW['test'][1])\n",
    "print('\\n')\n",
    "calculate_DecisionTrees(IMDB_FBOW['test'][0], IMDB_FBOW['test'][1], 200, 800, 90)\n",
    "print('\\n')\n",
    "calculate_SVC(IMDB_FBOW['test'][0], IMDB_FBOW['test'][1], 2, 1e-06)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
